{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f554972-a84a-441c-8565-589f338a34c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import datetime\n",
    "import os\n",
    "import pprint\n",
    "import random\n",
    "\n",
    "import ee\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import openet.core\n",
    "\n",
    "from IPython.display import Image, display\n",
    "import ipyplot\n",
    "\n",
    "# gsutil -m cp \"gs://openet_temp/skip_scene_stats/2025/p1*.csv\" ./stats/2025/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f809b90-fa61-43b6-b3c3-cb365ec6ed09",
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Initialize(\n",
    "    project='ee-cmorton',\n",
    "    opt_url='https://earthengine-highvolume.googleapis.com'\n",
    ")\n",
    "\n",
    "stats_ws = os.path.join(os.getcwd(), 'stats')\n",
    "if not os.path.isdir(stats_ws):\n",
    "    os.makedirs(stats_ws)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f175af-c860-4ddf-b9d1-72224e0f7445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Denmark WRS2 list\n",
    "wrs2_list = [\n",
    "    'p198r021', 'p198r020', \n",
    "    'p197r022', 'p197r021', 'p197r020', \n",
    "    'p196r022', 'p196r021', 'p196r020', \n",
    "    'p195r022', 'p195r021', \n",
    "    'p194r021', 'p194r022'\n",
    "]\n",
    "\n",
    "wrs2_skip_list = [\n",
    "    # 'p010r030', \n",
    "]\n",
    "\n",
    "# wrs2_list = sorted(\n",
    "#     ee.FeatureCollection('projects/openet/assets/features/wrs2/custom')\n",
    "#     .filterBounds(ee.Geometry.BBox(-124, 26, -67.9, 50))\n",
    "#     .filter(ee.Filter.inList('wrs2_tile', wrs2_skip_list).Not())\n",
    "#     .aggregate_histogram('wrs2_tile').keys().getInfo(),\n",
    "#     reverse=True\n",
    "# )\n",
    "# # print(len(wrs2_list))\n",
    "\n",
    "ocean_wrs2_list = [\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e58b512-59c5-473d-8cd5-447317382df8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "land_mask = ee.Image('projects/openet/assets/features/water_mask').Not()\n",
    "# Apply the NLCD/NALCMS water mask (anywhere it is water, set the ocean mask \n",
    "# land_mask = land_mask.where(ee.Image(\"USGS/NLCD_RELEASES/2020_REL/NALCMS\").unmask(18).eq(18), 0)\n",
    "# land_mask = land_mask.And(ee.Image(\"USGS/NLCD_RELEASES/2020_REL/NALCMS\").unmask(18).neq(18))\n",
    "\n",
    "rgb_bands = {\n",
    "    'LT04': ['SR_B3', 'SR_B2', 'SR_B1'],\n",
    "    'LT05': ['SR_B3', 'SR_B2', 'SR_B1'],\n",
    "    'LE07': ['SR_B3', 'SR_B2', 'SR_B1'],\n",
    "    'LC08': ['SR_B4', 'SR_B3', 'SR_B2'],\n",
    "    'LC09': ['SR_B4', 'SR_B3', 'SR_B2'],\n",
    "}\n",
    "\n",
    "# 0 - white, 1 - no fill (green), 2 - shadow (dark blue), 3 - snow (light blue), 4 - cloud (light gray), 5 - water (purple), 6 - ocean mask\n",
    "fmask_palette = \"ffffff, 9effa1, blue, 00aff2, dddddd, purple, bfbfbf\"\n",
    "fmask_max = 6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cdaea1-e7ee-4ed3-a392-4f44f02bd298",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fmask(landsat_img):\n",
    "    # Add the fmask image on top of the true color image\n",
    "    qa_img = landsat_img.select('QA_PIXEL')\n",
    "    fill_mask = qa_img.bitwiseAnd(1).neq(0)                  # bits: 0\n",
    "    dilate_mask = qa_img.rightShift(1).bitwiseAnd(1).neq(0)  # bits: 1\n",
    "    cirrus_mask = qa_img.rightShift(2).bitwiseAnd(1).neq(0)  # bits: 2\n",
    "    cloud_mask = qa_img.rightShift(3).bitwiseAnd(1).neq(0)   # bits: 3\n",
    "    shadow_mask = qa_img.rightShift(4).bitwiseAnd(1).neq(0)  # bits: 4\n",
    "    snow_mask = qa_img.rightShift(5).bitwiseAnd(1).neq(0)    # bits: 5\n",
    "    clear_mask = qa_img.rightShift(6).bitwiseAnd(1).neq(0)   # bits: 6\n",
    "    water_mask = qa_img.rightShift(7).bitwiseAnd(1).neq(0)   # bits: 7\n",
    "    cloud_conf = qa_img.rightShift(8).bitwiseAnd(3)          # bits: 8, 9\n",
    "    shadow_conf = qa_img.rightShift(10).bitwiseAnd(3)        # bits: 10, 11\n",
    "    snow_conf = qa_img.rightShift(12).bitwiseAnd(3)          # bits: 12, 13\n",
    "    cirrus_conf = qa_img.rightShift(14).bitwiseAnd(3)        # bits: 14, 15\n",
    "\n",
    "    # Saturated pixels\n",
    "    # Flag as saturated if any of the RGB bands are saturated\n",
    "    #   or change .gt(0) to .gt(7) to flag if all RGB bands are saturated\n",
    "    # Comment out rightShift line to flag if saturated in any band\n",
    "    bitshift = ee.Dictionary({'LANDSAT_4': 0, 'LANDSAT_5': 0, 'LANDSAT_7': 0, 'LANDSAT_8': 1, 'LANDSAT_9': 1});\n",
    "    saturated_mask = (\n",
    "        landsat_img.select('QA_RADSAT')\n",
    "        .rightShift(ee.Number(bitshift.get(ee.String(landsat_img.get('SPACECRAFT_ID'))))).bitwiseAnd(7)\n",
    "        .gt(0)\n",
    "    )\n",
    "    \n",
    "    # Old \"Fmask\" style image\n",
    "    fmask_img = (\n",
    "        qa_img.multiply(0)\n",
    "        .where(landsat_img.select(['SR_B4']).mask().eq(0), 1)\n",
    "        # .where(saturated_mask, 6)\n",
    "        .where(water_mask, 5)\n",
    "        .where(shadow_mask, 2)\n",
    "        .where(snow_mask, 3)\n",
    "        .where(cloud_mask.Or(dilate_mask).Or(cirrus_mask), 4)\n",
    "        # .add(shadow_mask.multiply(2))\n",
    "        # .add(snow_mask.multiply(3))\n",
    "        # .add(cloud_mask.Or(dilate_mask).Or(cirrus_mask).multiply(4))\n",
    "        # .add(cloud_mask.Or(dilate_mask).multiply(4))\n",
    "        # .add(cloud_mask.And(cloud_conf).multiply(4))\n",
    "        # .add(water_mask.multiply(5))\n",
    "    )\n",
    "    \n",
    "    return fmask_img.updateMask(fmask_img.neq(0)).rename(['fmask'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784957e0-dec8-41ca-a833-9776631cfa2b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Clean up the scene skip list file\n",
    "# skip_path = '../v2p1_denmark.csv'\n",
    "# print(f'\\n{skip_path}')\n",
    "\n",
    "# with open(skip_path, 'r') as csv_f:\n",
    "#     scene_skip_lines = csv_f.readlines()\n",
    "# scene_skip_header = scene_skip_lines.pop(0)\n",
    "\n",
    "# # Drop the comments and empty lines\n",
    "# scene_skip_lines = [line.strip() for line in scene_skip_lines if line.strip() and line[0] != '#']\n",
    "\n",
    "# # Sort by date then by tile\n",
    "# scene_skip_lines = sorted(scene_skip_lines, key=lambda x:x.split(',')[0].split('_')[-1] + '_' + x.split(',')[0].split('_')[-2])\n",
    "\n",
    "# # Identify duplicate scene IDs (as opposed to duplicate lines)\n",
    "# # Note, this block is not removing any lines, just printing\n",
    "# print('Duplicate Scene IDs:')\n",
    "\n",
    "# if len({l.split(',')[0] for l in scene_skip_lines}) != len(scene_skip_lines):\n",
    "#     for item, count in collections.Counter([l.split(',')[0] for l in scene_skip_lines]).items():\n",
    "#         if count > 1:\n",
    "#             print(item)\n",
    "\n",
    "# # Identify lines with no reason\n",
    "# print('\\nMissing reason Scene IDs:')\n",
    "# for l in scene_skip_lines:\n",
    "#     if ',' not in l:\n",
    "#         print(l)\n",
    "#     elif l.split(',')[1].strip() == '':\n",
    "#         print(l)\n",
    "#     elif len(l.split(',')) > 2:\n",
    "#         print(l)\n",
    "\n",
    "# # # Identify duplicate lines (not duplicate SCENE IDs)\n",
    "# # if len({line for line in scene_skip_lines}) != len(scene_skip_lines):\n",
    "# #     print('Duplicate Lines:')\n",
    "# #     for item, count in collections.Counter(scene_skip_lines).items():\n",
    "# #         if count > 1:\n",
    "# #             print(item)\n",
    "# # \n",
    "# #     # # Uncomment to have the tool remove duplicate lines\n",
    "# #     # scene_remove_lines = []\n",
    "# #     # for item, count in collections.Counter(scene_skip_lines).items():\n",
    "# #     #     if count > 1:\n",
    "# #     #         scene_remove_lines.append(item)\n",
    "# #     #         # print(item)\n",
    "# #      \n",
    "# #     # # Does this only remove the first one?\n",
    "# #     # if scene_remove_lines:\n",
    "# #     #     print(f'Removing {len(scene_remove_lines)} duplicate lines in file')\n",
    "# #     #     for line in scene_remove_lines:\n",
    "# #     #         print(line)\n",
    "# #     #         scene_skip_lines.remove(line)\n",
    "# # \n",
    "# # # Then recheck for duplicate SCENE_IDs (but different notes or dates)\n",
    "# # scenes = {line.split(',')[0] for line in scene_skip_lines}           \n",
    "# # if len(scenes) != len(scene_skip_lines):\n",
    "# #     print('Duplicate scene IDs still in file')\n",
    "    \n",
    "# print('\\nWriting updated scene skip list CSV')\n",
    "# with open(skip_path.replace('.csv', '_sorted.csv'), 'w') as csv_f:\n",
    "#     csv_f.write(scene_skip_header)\n",
    "#     for i, line in enumerate(scene_skip_lines):\n",
    "#         csv_f.write(line + '\\n')\n",
    "\n",
    "# print('\\nDone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7135e03-10dd-4577-9b6d-11b1383f5feb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a715e43-a9d7-43ec-8a56-c42fb50dc594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove existing images that are in the skip list\n",
    "scene_skip_url = '../v2p1_denmark.csv'\n",
    "#scene_skip_url = 'https://raw.githubusercontent.com/cgmorton/scene-skip-list/main/v2p1_denmark.csv'\n",
    "scene_skip_list = list(pd.read_csv(scene_skip_url)['SCENE_ID'].values)\n",
    "scene_skip_list = sorted(scene_skip_list, key=lambda k: k.split('_')[-2], reverse=True)\n",
    "print(f'Skip list images: {len(scene_skip_list)}')\n",
    "\n",
    "collections = [\n",
    "    'projects/openet/assets/ssebop/eu/era5land/landsat/v2_1',\n",
    "]\n",
    "\n",
    "for coll_id in collections:\n",
    "    print(f'\\n{coll_id}')\n",
    "    scene_id_list = set(\n",
    "        ee.ImageCollection(coll_id)\n",
    "        # .filterDate('2022-09-01', '2025-01-01')\n",
    "        # .filterBounds(ee.Geometry.BBox(-125, 25, -124, 42))\n",
    "        # .filterBounds(ee.Geometry.BBox(-90, 25, -65, 50))\n",
    "        .aggregate_array('system:index').getInfo()\n",
    "    )\n",
    "    print(f'  Images: {len(scene_id_list)}')\n",
    "\n",
    "    for scene_id in scene_skip_list:\n",
    "        # print(scene_id)\n",
    "        if scene_id.lower() in scene_id_list:\n",
    "            image_id = f'{coll_id}/{scene_id.lower()}'\n",
    "            print(f'Delete {image_id}')\n",
    "            try:\n",
    "                ee.data.deleteAsset(image_id)\n",
    "            except:\n",
    "                print('  could not delete asset, skipping')\n",
    "                continue\n",
    "\n",
    "print('\\nDone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c84e84-1fbe-4475-98aa-f3e5cc94d5f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61faa3e-a250-486c-b34f-cb4b57fe6971",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Print scenes with high masked count percentages\n",
    "# count_threshold_pct_min = 75\n",
    "# count_threshold_pct_max = 80\n",
    "count_threshold_pct_min = 70\n",
    "count_threshold_pct_max = 101\n",
    "\n",
    "start_year = 2017\n",
    "end_year = 2025\n",
    "years = list(range(start_year, end_year + 1))\n",
    "#months = [6, 7, 8]\n",
    "months = []\n",
    "\n",
    "print_count = 10\n",
    "image_size = 1200\n",
    "#image_size = 700\n",
    "\n",
    "# Read in the scene skip list\n",
    "scene_skip_url = '../v2p1_denmark.csv'\n",
    "# scene_skip_url = 'https://raw.githubusercontent.com/cgmorton/scene-skip-list/main/v2p1_denmark.csv'\n",
    "scene_skip_df = pd.read_csv(scene_skip_url)\n",
    "scene_skip_list = list(scene_skip_df['SCENE_ID'].values)\n",
    "print(f'Skip list images: {len(scene_skip_list)}')\n",
    "\n",
    "# scene_cloudscore_url = '../v2p1_cloudscore.csv'\n",
    "# # scene_cloudscore_url = 'https://raw.githubusercontent.com/cgmorton/scene-skip-list/main/v2p1_cloudscore.csv'\n",
    "# scene_cloudscore_list = list(pd.read_csv(scene_cloudscore_url)['SCENE_ID'].values)\n",
    "# print(f'Skip cloudscore images: {len(scene_cloudscore_list)}')\n",
    "\n",
    "\n",
    "print('Reading image stats CSV files')\n",
    "stats_df_list = []\n",
    "for wrs2_tile in wrs2_list:\n",
    "    # if int(wrs2_tile[1:4]) not in range(10, 25):\n",
    "    #     continue\n",
    "        \n",
    "    for year in range(start_year, end_year + 1):\n",
    "        wrs2_stats_path = os.path.join(stats_ws, f'{year}', f'{wrs2_tile}_{year}.csv')\n",
    "        if not os.path.isfile(wrs2_stats_path):\n",
    "            # print(f'  {wrs2_tile}_{year} - Missing stats CSV, skipping')\n",
    "            continue\n",
    "        try:\n",
    "            wrs2_stats_df = pd.read_csv(wrs2_stats_path, index_col=False)\n",
    "        except Exception as e:\n",
    "            print(f'  {wrs2_tile}_{year} - Error reading CSV, skipping')\n",
    "            continue\n",
    "        if wrs2_stats_df.empty:\n",
    "            continue\n",
    "        wrs2_stats_df['DATE'] = wrs2_stats_df['SCENE_ID'].str.slice(12, 20)\n",
    "        wrs2_stats_df['WRS2'] = 'p' + wrs2_stats_df['SCENE_ID'].str.slice(5, 8) + 'r' + wrs2_stats_df['SCENE_ID'].str.slice(8, 11)\n",
    "        stats_df_list.append(wrs2_stats_df)\n",
    "\n",
    "stats_df = pd.concat(stats_df_list)\n",
    "\n",
    "# Add the high CLOUD_COVER_LAND scenes to the skip list but don't remove from the dataframe\n",
    "scene_skip_list.extend(stats_df[stats_df['CLOUD_COVER_LAND'] >= 71]['SCENE_ID'].values)\n",
    "\n",
    "# Skip the Landsat 7 scenes in 2023\n",
    "l7_2022_mask = (\n",
    "    (stats_df['DATE'].str.slice(0,4) >= '2022') &\n",
    "    (stats_df['SCENE_ID'].str.slice(0,4) == 'LE07')\n",
    ")\n",
    "stats_df = stats_df[~l7_2022_mask]\n",
    "\n",
    "# Only check specific months scenes\n",
    "if months:\n",
    "    stats_df = stats_df[stats_df['DATE'].str.slice(4,6).astype(int).isin(months)]\n",
    "\n",
    "# Compute the ratios\n",
    "# stats_df['ACCA_COUNT_RATIO'] = stats_df['ACCA_PIXELS'] / stats_df['TOTAL_PIXELS']\n",
    "stats_df['SNOW_COUNT_RATIO'] = stats_df['SNOW_PIXELS'] / stats_df['TOTAL_PIXELS']\n",
    "# stats_df['SHADOW_COUNT_RATIO'] = stats_df['SHADOW_PIXELS'] / stats_df['TOTAL_PIXELS']\n",
    "stats_df['WATER_COUNT_RATIO'] = stats_df['WATER_PIXELS'] / stats_df['TOTAL_PIXELS']\n",
    "stats_df['MASKED_PIXELS'] = (\n",
    "    stats_df['CLOUD_PIXELS'] + stats_df['CIRRUS_PIXELS'] + stats_df['DILATE_PIXELS']\n",
    "    + stats_df['SHADOW_PIXELS']\n",
    "    + stats_df['SNOW_PIXELS']\n",
    "    + stats_df['WATER_PIXELS']\n",
    "    + stats_df['ACCA_PIXELS']\n",
    "    # + stats_df['SATURATED_PIXELS']\n",
    ")\n",
    "stats_df['CLOUD_COUNT_RATIO'] = stats_df['MASKED_PIXELS'] / stats_df['TOTAL_PIXELS']\n",
    "# stats_df['CLOUD_COUNT_RATIO'] = stats_df['UNMASKED_PIXELS'] / stats_df['TOTAL_PIXELS']\n",
    "\n",
    "print(f'  {len(stats_df.count(axis=1))}')\n",
    "\n",
    "# Work through the tiles based on which ones already have the most skipped scenes\n",
    "wrs2_tiles = list(stats_df.groupby(['WRS2'])['SCENE_ID'].count().sort_values(ascending=False).index)\n",
    "# wrs2_tiles = ['']\n",
    "\n",
    "new_skip_scenes = []\n",
    "new_skip_count = 0\n",
    "\n",
    "wrs2_i = 0\n",
    "\n",
    "# for wrs2 in reversed(wrs2_tiles):\n",
    "# for wrs2 in sorted(wrs2_tiles):\n",
    "# for wrs2 in reversed(sorted(wrs2_tiles)):\n",
    "for wrs2 in random.sample(wrs2_tiles, len(wrs2_tiles)):\n",
    "    if wrs2_i >= 20:\n",
    "        break\n",
    "    if wrs2_skip_list and (wrs2 in wrs2_skip_list):\n",
    "        continue\n",
    "    # if california_wrs2_list and (wrs2 not in california_wrs2_list) and wrs2 not in ['p042r033']:\n",
    "    #     continue\n",
    "    # if int(wrs2[1:4]) != 10:\n",
    "    #     continue\n",
    "    # if int(wrs2[1:4]) != 24:\n",
    "    #     continue\n",
    "    # if int(wrs2[5:8]) >= 30:\n",
    "    #     continue\n",
    "    #if int(wrs2[5:8]) == 25 or int(wrs2[5:8]) == 50:\n",
    "    #   continue\n",
    "    print(wrs2)\n",
    "    \n",
    "    wrs2_path = int(wrs2[1:4])\n",
    "    wrs2_row = int(wrs2[5:8])\n",
    "    wrs2_tgt = f'{wrs2_path:03d}{wrs2_row:03d}'\n",
    "    wrs2_above = f'{wrs2_path:03d}{wrs2_row-1:03d}'\n",
    "    wrs2_below = f'{wrs2_path:03d}{wrs2_row+1:03d}'    \n",
    "\n",
    "    wrs2_stats_df = stats_df[stats_df['WRS2'] == wrs2].copy()\n",
    "    # Applying skip list here so that main stats DF has all scenes\n",
    "    wrs2_stats_df = wrs2_stats_df[~wrs2_stats_df['SCENE_ID'].isin(scene_skip_list)]\n",
    "    #wrs2_stats_df = wrs2_stats_df[~wrs2_stats_df['SCENE_ID'].isin(scene_cloudscore_list)]\n",
    "    \n",
    "    # Filter on the overall cloud count ratio\n",
    "    wrs2_stats_df = wrs2_stats_df[wrs2_stats_df['CLOUD_COUNT_RATIO'] < (count_threshold_pct_max / 100)]\n",
    "    wrs2_stats_df = wrs2_stats_df[wrs2_stats_df['CLOUD_COUNT_RATIO'] >= (count_threshold_pct_min / 100)]\n",
    "    wrs2_stats_df.sort_values('CLOUD_COUNT_RATIO', ascending=False, inplace=True)\n",
    "\n",
    "    # # Filter on the CLOUD_COVER_LAND property\n",
    "    # wrs2_stats_df = wrs2_stats_df[wrs2_stats_df['CLOUD_COVER_LAND'] < 71]\n",
    "    # wrs2_stats_df = wrs2_stats_df[wrs2_stats_df['CLOUD_COVER_LAND'] >= 69]\n",
    "    #wrs2_stats_df.sort_values('CLOUD_COVER_LAND', ascending=False, inplace=True)\n",
    "\n",
    "    if len(wrs2_stats_df.count(axis=1)) == 0:\n",
    "        continue\n",
    "    print(f'{wrs2} - {len(wrs2_stats_df.count(axis=1))}')\n",
    "\n",
    "    wrs2_skip_scenes = []\n",
    "    wrs2_skip_count = 0\n",
    "    \n",
    "    # for i, row in wrs2_stats_df.iterrows():\n",
    "    for i, row in wrs2_stats_df.sample(n=min(print_count, len(wrs2_stats_df.index))).iterrows():\n",
    "\n",
    "        scene_id = row[\"SCENE_ID\"].upper()\n",
    "\n",
    "        above_scene_id = scene_id.upper().replace(wrs2_tgt, wrs2_above)\n",
    "        above_stats_df = stats_df.loc[stats_df['SCENE_ID'] == above_scene_id]\n",
    "        if len(above_stats_df):\n",
    "            above_cloud_pct = float(above_stats_df.iloc[0]['CLOUD_COVER_LAND'])\n",
    "        else:\n",
    "            above_cloud_pct = None\n",
    "            \n",
    "        below_scene_id = scene_id.upper().replace(wrs2_tgt, wrs2_below)\n",
    "        below_stats_df = stats_df.loc[stats_df['SCENE_ID'] == below_scene_id]\n",
    "        if len(below_stats_df):\n",
    "            below_cloud_pct = float(below_stats_df.iloc[0]['CLOUD_COVER_LAND'])\n",
    "        else:\n",
    "            below_cloud_pct = None\n",
    "\n",
    "        # # Only show scenes that have above & below both skipped or None\n",
    "        # if (((above_scene_id not in scene_skip_list) and (above_cloud_pct is not None)) or \n",
    "        #     ((below_scene_id not in scene_skip_list) and (below_cloud_pct is not None))):\n",
    "        #     continue   \n",
    "\n",
    "        # # Only show scenes that have either above & below skipped or None\n",
    "        # if (((above_scene_id not in scene_skip_list) and (above_cloud_pct is not None)) and \n",
    "        #     ((below_scene_id not in scene_skip_list) and (below_cloud_pct is not None))):\n",
    "        #     continue   \n",
    "            \n",
    "        landsat_type = scene_id.split('_')[0].upper()\n",
    "        landsat_img = ee.Image(f'LANDSAT/{landsat_type}/C02/T1_L2/{scene_id}')\n",
    "        landsat_region = landsat_img.geometry().bounds(1, 'EPSG:4326')\n",
    "        landsat_sr_img = landsat_img.select(rgb_bands[landsat_type]).multiply([0.0000275]).add([-0.2])\n",
    "\n",
    "        # Landsat true color image\n",
    "        landsat_url = (\n",
    "            landsat_sr_img.where(land_mask.unmask().eq(0), 0.25)\n",
    "            .getThumbURL({'min': 0.0, 'max': 0.30, 'gamma': 1.25, 'region': landsat_region, 'dimensions': image_size})\n",
    "        )\n",
    "    \n",
    "        # Landsat true color with Fmask\n",
    "        fmask_url = (\n",
    "            landsat_sr_img.where(land_mask.unmask().eq(0), 0.25).visualize(min=0, max=0.3, gamma=1.25)\n",
    "            .blend(fmask(landsat_img).where(land_mask.unmask().eq(0), fmask_max).visualize(bands='fmask', min=0, max=fmask_max, palette=fmask_palette))\n",
    "            .getThumbURL({'region': landsat_region, 'dimensions': image_size})\n",
    "        )\n",
    "    \n",
    "        print('#'*80)\n",
    "        print(\n",
    "            f'  {scene_id}  {row[\"TOTAL_PIXELS\"]:>10d}  {row[\"UNMASKED_PIXELS\"]:>10d}'\n",
    "            f'  ({row[\"CLOUD_COUNT_RATIO\"]:>0.2f}) ({row[\"SNOW_COUNT_RATIO\"]:>0.2f}) {row[\"CLOUD_COVER_LAND\"]}'\n",
    "            f'  {row[\"SR_RED\"]:0.2f}  {row[\"SR_GREEN\"]:0.2f}  {row[\"SR_BLUE\"]:0.2f}'\n",
    "        )\n",
    "        ipyplot.plot_images([landsat_url, fmask_url], img_width=image_size)\n",
    "    \n",
    "        # Show the images above and below the target wrs2\n",
    "        above_img = ee.Image(f'LANDSAT/{landsat_type}/C02/T1_L2/{above_scene_id}')\n",
    "        above_region = above_img.geometry().bounds(1, 'EPSG:4326')\n",
    "        above_sr_img = above_img.select(rgb_bands[landsat_type]).multiply([0.0000275]).add([-0.2])\n",
    "        try:\n",
    "            above_url = (\n",
    "                above_sr_img.where(land_mask.unmask().eq(0), 0.25).visualize(min=0, max=0.3, gamma=1.25)\n",
    "                .blend(fmask(above_img).where(land_mask.unmask().eq(0), fmask_max).visualize(bands='fmask', min=0, max=fmask_max, palette=fmask_palette))\n",
    "                .getThumbURL({'region': above_region, 'dimensions': image_size})\n",
    "            )\n",
    "        except:\n",
    "            above_url = None\n",
    "            \n",
    "        below_img = ee.Image(f'LANDSAT/{landsat_type}/C02/T1_L2/{below_scene_id}')\n",
    "        below_region = below_img.geometry().bounds(1, 'EPSG:4326')\n",
    "        below_sr_img = below_img.select(rgb_bands[landsat_type]).multiply([0.0000275]).add([-0.2])\n",
    "        try:\n",
    "            below_url = (\n",
    "                below_sr_img.where(land_mask.unmask().eq(0), 0.25).visualize(min=0, max=0.3, gamma=1.25)\n",
    "                .blend(fmask(below_img).where(land_mask.unmask().eq(0), fmask_max).visualize(bands='fmask', min=0, max=fmask_max, palette=fmask_palette))\n",
    "                .getThumbURL({'region': below_region, 'dimensions': image_size})\n",
    "            )\n",
    "        except:\n",
    "            below_url = None\n",
    "        \n",
    "        above_skipped = f' (skipped)' if above_scene_id in scene_skip_list else ''   \n",
    "        below_skipped = f' (skipped)' if below_scene_id in scene_skip_list else ''\n",
    "        \n",
    "        if above_url and below_url:\n",
    "            print(f'{below_scene_id} ({below_cloud_pct}){below_skipped}  {above_scene_id} ({above_cloud_pct}){above_skipped}')\n",
    "            ipyplot.plot_images([below_url, above_url], img_width=image_size)\n",
    "        elif above_url:\n",
    "            print(f'{above_scene_id} ({above_cloud_pct}){above_skipped}')\n",
    "            ipyplot.plot_images([above_url], img_width=image_size)\n",
    "        elif below_url:\n",
    "            print(f'{below_scene_id} ({below_cloud_pct}){below_skipped}')\n",
    "            ipyplot.plot_images([below_url], img_width=image_size)\n",
    "    \n",
    "        wrs2_skip_scenes.append(scene_id)\n",
    "        wrs2_skip_count += 1\n",
    "        if wrs2_skip_count >= print_count:\n",
    "            break\n",
    "\n",
    "    if wrs2_skip_scenes:\n",
    "        wrs2_i += 1\n",
    "        for scene_id in wrs2_skip_scenes:\n",
    "            print(scene_id)\n",
    "        new_skip_scenes.extend(wrs2_skip_scenes)\n",
    "\n",
    "print('\\nNew Skip Scenes')\n",
    "if new_skip_scenes:\n",
    "    for scene_id in new_skip_scenes:\n",
    "        print(scene_id)\n",
    "\n",
    "print('\\nDone')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f528d7d-456d-40c5-ae04-da87629da0c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
