{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb335b1-2548-4c0d-beb4-bcd391a5e63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import multiprocessing\n",
    "import os\n",
    "import pprint\n",
    "import time\n",
    "\n",
    "import ee\n",
    "import pandas as pd\n",
    "from google.cloud import storage\n",
    "#import retry\n",
    "\n",
    "from IPython.display import Image, display\n",
    "#import ipyplot\n",
    "\n",
    "# gsutil -m rm \"gs://openet_temp/skip_scene_stats/2024/*.csv\"\n",
    "# gsutil -m cp \"gs://openet_temp/skip_scene_stats/2024/*.csv\" ./stats/2024/\n",
    "\n",
    "BUCKET_NAME = 'openet_temp'\n",
    "BUCKET_FOLDER = 'skip_scene_stats'\n",
    "storage_client = storage.Client(project='openet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fced3c-d104-4f5a-a59e-236f2421030e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Initialize(\n",
    "    #ee.ServiceAccountCredentials('_', key_file='../../keys/openet-gee.json')\n",
    "    ee.ServiceAccountCredentials('_', key_file='../../keys/openet-dri-gee.json')\n",
    "    #project='ee-cmorton',\n",
    "    #opt_url='https://earthengine-highvolume.googleapis.com'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581e108c-cb42-4be4-9f31-79f358aed7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Ocean mask is True for water, so flip it for updateMask call so that land pixels are 1\n",
    "land_mask = ee.Image('projects/openet/assets/features/water_mask').Not()\n",
    "# Apply the NLCD/NALCMS water mask (anywhere it is water, set the ocean mask \n",
    "land_mask = land_mask.where(ee.Image(\"USGS/NLCD_RELEASES/2020_REL/NALCMS\").unmask(18).eq(18), 0)\n",
    "# land_mask = land_mask.And(ee.Image(\"USGS/NLCD_RELEASES/2020_REL/NALCMS\").unmask(18).neq(18))\n",
    "\n",
    "# land_mask = ee.Image('projects/openet/assets/meteorology/conus404/ancillary/land_mask')\n",
    "\n",
    "stats_ws = os.path.join(os.getcwd(), 'stats')\n",
    "if not os.path.isdir(stats_ws):\n",
    "    os.makedirs(stats_ws)\n",
    "\n",
    "# # Use the OpenET ssebop collection for building the WRS2 list for now\n",
    "# wrs2_list = sorted(\n",
    "#     # ee.ImageCollection('projects/openet/assets/ssebop/conus/gridmet/landsat/c02')\n",
    "#     # ee.ImageCollection('projects/openet/assets/intercomparison/ssebop/landsat/c02/v0p2p6')\n",
    "#     ee.ImageCollection('projects/usgs-gee-nhm-ssebop/assets/ssebop/landsat/c02')\n",
    "#     .filterDate('2020-01-01', '2024-01-01')\n",
    "#     .aggregate_histogram('wrs2_tile').keys().getInfo(),\n",
    "#     reverse=True\n",
    "# )\n",
    "# wrs2_list = wrs2_list + ['p018r028']\n",
    "# # print(len(wrs2_list))\n",
    "\n",
    "# # Use the OpenET ssebop collection for building the WRS2 list for now\n",
    "# wrs2_subset_list = sorted(\n",
    "#     # ee.ImageCollection('projects/openet/assets/intercomparison/ssebop/landsat/c02/v0p2p6')\n",
    "#     ee.ImageCollection('projects/usgs-gee-nhm-ssebop/assets/ssebop/landsat/c02')\n",
    "#     .filterDate('2020-01-01', '2024-01-01')\n",
    "#     .aggregate_histogram('wrs2_tile').keys().getInfo(),\n",
    "#     reverse=True\n",
    "# )\n",
    "# wrs2_subset_list = wrs2_subset_list + ['p018r028']\n",
    "# wrs2_list = [wrs2 for wrs2 in wrs2_subset_list if wrs2 not in wrs2_list]\n",
    "# print(len(wrs2_list))\n",
    "\n",
    "wrs2_skip_list = [\n",
    "    'p050r026',  # Vancouver Island\n",
    "    'p048r028',  # OR/WA Coast\n",
    "    'p042r037',  # San Nicholas Island, California\n",
    "    'p040r040', 'p039r040',  # Isla Guadalupe\n",
    "    'p038r043', 'p036r043',  # Baja coast\n",
    "    'p019r040', 'p018r040',  # West Florida coast\n",
    "    'p016r043', 'p015r043',  # South Florida coast\n",
    "    'p014r041', 'p014r042', 'p014r043',  # East Florida coast\n",
    "    'p013r034', 'p013r035', 'p013r036',  # North Carolina Outer Banks\n",
    "    'p011r032',  # Rhode Island coast\n",
    "    'p010r030',  # Maine\n",
    "    # Caribbean tiles\n",
    "    'p014r041', 'p014r042', 'p013r041', 'p013r042',  # Bahamas\n",
    "    'p012r042', 'p012r043', 'p011r042', 'p011r043',  # Bahamas\n",
    "    'p013r043',  # Bahamas (main island)\n",
    "    'p006r037', 'p006r038',  # Bermuda\n",
    "    'p017r044', 'p016r044', 'p015r044', 'p014r044',  # Cuba\n",
    "    'p013r044', 'p012r044', 'p011r044', 'p010r044',  # Cuba/Bahamas\n",
    "]\n",
    "\n",
    "wrs2_list = sorted(\n",
    "    ee.FeatureCollection('projects/openet/assets/features/wrs2/custom')\n",
    "    #.filterBounds(ee.Geometry.BBox(-125.5, 25, -65.5, 52))\n",
    "    .filterBounds(ee.Geometry.BBox(-127, 24, -63, 52))\n",
    "    .filter(ee.Filter.inList('wrs2_tile', wrs2_skip_list).Not())\n",
    "    .aggregate_histogram('wrs2_tile').keys().getInfo(),\n",
    "    reverse=True\n",
    ")\n",
    "print(len(wrs2_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6176e227-a4f7-4777-a092-6971ef04bf8b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def covering_grid(image, scale):\n",
    "#     # TODO: Get the offsets from the image transform some how?\n",
    "#     x_offset = 15\n",
    "#     y_offset = 15\n",
    "#     # Get the upper left coordinates from the transform\n",
    "#     image_geom = image.select([0]).geometry()\n",
    "#     image_crs = image.select([0]).projection().crs()\n",
    "#     xy = ee.Array(image_geom.bounds(1, image_crs).coordinates().get(0)).transpose().toList()\n",
    "#     # Compute the max and min X and Y values for defining the extent\n",
    "#     xmin = ee.Number(ee.List(xy.get(0)).reduce(ee.Reducer.min()))\n",
    "#     ymin = ee.Number(ee.List(xy.get(1)).reduce(ee.Reducer.min()))\n",
    "#     xmax = ee.Number(ee.List(xy.get(0)).reduce(ee.Reducer.max()))\n",
    "#     ymax = ee.Number(ee.List(xy.get(1)).reduce(ee.Reducer.max()))\n",
    "#     # Adjust the extent parameters to be buffered and snapped to the Landsat grid (15, 15) and gridsize\n",
    "#     xmin = xmin.subtract(x_offset).divide(scale).floor().multiply(scale).add(x_offset)\n",
    "#     ymin = ymin.subtract(y_offset).divide(scale).floor().multiply(scale).add(y_offset)\n",
    "#     xmax = xmax.subtract(x_offset).divide(scale).ceil().multiply(scale).add(x_offset)\n",
    "#     ymax = ymax.subtract(y_offset).divide(scale).ceil().multiply(scale).add(y_offset)\n",
    "#     # Compute the number of columns and rows needed to generate the grid\n",
    "#     # Subtract 1 since these are the lower left indices\n",
    "#     num_cols = xmax.subtract(xmin).abs().divide(scale).subtract(1)\n",
    "#     num_rows = ymax.subtract(ymin).abs().divide(scale).subtract(1)\n",
    "#     # Build the list of column and row lower left coordinates\n",
    "#     cols = ee.List.sequence(xmin, num_cols.multiply(scale).add(xmin), scale) \n",
    "#     rows = ee.List.sequence(ymin, num_rows.multiply(scale).add(ymin), scale)\n",
    "    \n",
    "#     # Build the grid feature collection\n",
    "#     def create_grid_coll(c):\n",
    "#         all_fts = ee.FeatureCollection([]) \n",
    "#         c_tag = ee.List(cols).indexOf(c)\n",
    "#         def build_row(r):\n",
    "#             cell_geom = ee.Geometry.Rectangle(\n",
    "#                 ee.List([ee.Number(c), ee.Number(r), ee.Number(c).add(scale), ee.Number(r).add(scale)]),\n",
    "#                 image_crs, False\n",
    "#             )\n",
    "#             return ee.Feature(cell_geom, {'col': c_tag, 'row': ee.List(rows).indexOf(r)})\n",
    "#         row_fts = ee.FeatureCollection(rows.map(build_row))\n",
    "        \n",
    "#         all_fts = all_fts.merge(row_fts)\n",
    "#         return all_fts\n",
    "    \n",
    "#     return ee.FeatureCollection(cols.map(create_grid_coll)).flatten()\n",
    "\n",
    "# # landsat_id = 'LANDSAT/LC09/C02/T1_L2/LC09_029027_20240413'\n",
    "# # pprint.pprint(covering_grid(ee.Image(landsat_id).select(['QA_PIXEL']), scale=10000).getInfo())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00651415-fd11-4433-8315-7f50eca88f07",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "refl_sr_bands = ['SR_RED', 'SR_GREEN', 'SR_BLUE', 'QA_PIXEL', 'QA_RADSAT']\n",
    "refl_sr_bands_dict = ee.Dictionary({\n",
    "    'LT04': ['SR_B3', 'SR_B2', 'SR_B1', 'QA_PIXEL', 'QA_RADSAT'],\n",
    "    'LT05': ['SR_B3', 'SR_B2', 'SR_B1', 'QA_PIXEL', 'QA_RADSAT'],\n",
    "    'LE07': ['SR_B3', 'SR_B2', 'SR_B1', 'QA_PIXEL', 'QA_RADSAT'],\n",
    "    'LC08': ['SR_B4', 'SR_B3', 'SR_B2', 'QA_PIXEL', 'QA_RADSAT'],\n",
    "    'LC09': ['SR_B4', 'SR_B3', 'SR_B2', 'QA_PIXEL', 'QA_RADSAT'],\n",
    "})\n",
    "refl_toa_bands_dict = ee.Dictionary({\n",
    "    'LT04': ['B3', 'B2', 'B1'],\n",
    "    'LT05': ['B3', 'B2', 'B1'],\n",
    "    'LE07': ['B3', 'B2', 'B1'],\n",
    "    'LC08': ['B4', 'B3', 'B2'],\n",
    "    'LC09': ['B4', 'B3', 'B2'],\n",
    "})\n",
    "# sr_coll_dict = ee.Dictionary({\n",
    "#     'LT05': ee.ImageCollection('LANDSAT/LT05/C02/T1_L2'),\n",
    "#     'LE07': ee.ImageCollection('LANDSAT/LE07/C02/T1_L2'),\n",
    "#     'LC08': ee.ImageCollection('LANDSAT/LC08/C02/T1_L2'),\n",
    "#     'LC09': ee.ImageCollection('LANDSAT/LC09/C02/T1_L2'),\n",
    "# })\n",
    "# toa_coll_dict = ee.Dictionary({\n",
    "#     'LT05': ee.ImageCollection('LANDSAT/LT05/C02/T1_TOA'),\n",
    "#     'LE07': ee.ImageCollection('LANDSAT/LE07/C02/T1_TOA'),\n",
    "#     'LC08': ee.ImageCollection('LANDSAT/LC08/C02/T1_TOA'),\n",
    "#     'LC09': ee.ImageCollection('LANDSAT/LC09/C02/T1_TOA'),\n",
    "# })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87634b0c-4731-4655-a3f8-23383c12eda0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def image_stats(landsat_img):\n",
    "    scene_id = ee.String(landsat_img.get('scene_id'))\n",
    "    landsat_type = scene_id.slice(0, 4)\n",
    "\n",
    "    # Note, we can't rename the TOA bands here since the simple cloud score is expecting a raw TOA image\n",
    "    landsat_toa_img = ee.Image(landsat_img.get('landsat_toa_img'))\n",
    "\n",
    "    default_stats = ee.Dictionary({\n",
    "        'SCENE_ID': scene_id,\n",
    "        'UNMASKED_PIXELS': -1, 'TOTAL_PIXELS': -1,\n",
    "        'CLOUD_PIXELS': -1, 'CIRRUS_PIXELS': -1, 'DILATE_PIXELS': -1, \n",
    "        'SHADOW_PIXELS': -1, 'SNOW_PIXELS': -1, 'WATER_PIXELS': -1,\n",
    "        'SR_RED': -1, 'SR_GREEN': -1, 'SR_BLUE': -1,\n",
    "        'UNMASKED_SR_RED': -1, 'UNMASKED_SR_GREEN': -1, 'UNMASKED_SR_BLUE': -1,\n",
    "        'TOA_RED': -1, 'TOA_GREEN': -1, 'TOA_BLUE': -1,\n",
    "        'UNMASKED_TOA_RED': -1, 'UNMASKED_TOA_GREEN': -1, 'UNMASKED_TOA_BLUE': -1,\n",
    "        'CLOUD_COVER_LAND': landsat_img.get('CLOUD_COVER_LAND'), \n",
    "        'MORAN_1K': -1, 'MORAN_2K': -1, 'MORAN_4K': -1, 'MORAN_8K': -1,\n",
    "        #'SSEBOP_ETF_count': -9999, 'SSEBOP_ETF_mean': -9999, \n",
    "    })\n",
    "\n",
    "    # Get the cloud mask (including the snow mask for now)\n",
    "    qa_img = ee.Image(landsat_img.select(['QA_PIXEL']))\n",
    "    cloud_mask = qa_img.rightShift(3).bitwiseAnd(1).neq(0)\n",
    "    fmask_mask = qa_img.rightShift(3).bitwiseAnd(1).neq(0)\n",
    "    \n",
    "    # if cirrus_flag:\n",
    "    cirrus_mask = qa_img.rightShift(2).bitwiseAnd(1).neq(0).And(fmask_mask.Not())\n",
    "    fmask_mask = fmask_mask.Or(cirrus_mask)\n",
    "    \n",
    "    # if dilate_flag:\n",
    "    dilate_mask = qa_img.rightShift(1).bitwiseAnd(1).neq(0).And(fmask_mask.Not())\n",
    "    fmask_mask = fmask_mask.Or(dilate_mask)\n",
    "\n",
    "    # if shadow_flag:\n",
    "    shadow_mask = qa_img.rightShift(4).bitwiseAnd(1).neq(0).And(fmask_mask.Not())\n",
    "    fmask_mask = fmask_mask.Or(shadow_mask)\n",
    "    \n",
    "    # if snow_flag:\n",
    "    snow_mask = qa_img.rightShift(5).bitwiseAnd(1).neq(0).And(fmask_mask.Not())\n",
    "    fmask_mask = fmask_mask.Or(snow_mask)\n",
    "\n",
    "    # if water_flag:\n",
    "    water_mask = qa_img.rightShift(7).bitwiseAnd(1).neq(0).And(fmask_mask.Not())\n",
    "\n",
    "    # CGM - This isn't working correctly, don't apply\n",
    "    # # # Apply a small erosion/dilation\n",
    "    # # fmask_mask = (\n",
    "    # #     fmask_mask\n",
    "    # #     .reduceNeighborhood(ee.Reducer.min(), ee.Kernel.circle(radius=1, units='pixels'))\n",
    "    # #     .reduceNeighborhood(ee.Reducer.max(), ee.Kernel.circle(radius=2, units='pixels'))\n",
    "    # #     # .reduceNeighborhood(ee.Reducer.min(), ee.Kernel.circle(radius=30, units='meters'))\n",
    "    # #     # .reduceNeighborhood(ee.Reducer.max(), ee.Kernel.circle(radius=60, units='meters'))\n",
    "    # #     # .reproject(qa_img.projection())\n",
    "    # # )\n",
    "\n",
    "    # Saturated mask (only keep unmasked saturated pixels)\n",
    "    # Flag as saturated if any of the RGB bands are saturated\n",
    "    #   or change .gt(0) to .gt(7) to flag if all RGB bands are saturated\n",
    "    # Comment out rightShift line to flag if saturated in any band\n",
    "    bitshift = ee.Dictionary({'LT04': 0, 'LT05': 0, 'LE07': 0, 'LC08': 1, 'LC09': 1});\n",
    "    saturated_mask = (\n",
    "        landsat_img.select('QA_RADSAT')\n",
    "        .rightShift(ee.Number(bitshift.get(landsat_type))).bitwiseAnd(7)\n",
    "        .gt(0)\n",
    "    )\n",
    "    saturated_mask = saturated_mask.where(fmask_mask, 0)\n",
    "\n",
    "    # Simple cloud score (ACCA)\n",
    "    # Only keep unmasked ACCA pixels\n",
    "    acca_mask = ee.Algorithms.Landsat.simpleCloudScore(landsat_toa_img).select(['cloud']).gte(100)\n",
    "    acca_mask = acca_mask.where(fmask_mask, 0)\n",
    "\n",
    "    # Flip to set cloudy pixels to 0 and clear to 1\n",
    "    fmask_update_mask = fmask_mask.Not()\n",
    "\n",
    "    rr_mean_params = {\n",
    "        'reducer': ee.Reducer.mean().unweighted(),\n",
    "        'geometry': qa_img.geometry(), \n",
    "        'crs': qa_img.projection().crs(), \n",
    "        'crsTransform': [30, 0, 15, 0, -30, 15],\n",
    "        'bestEffort': False,\n",
    "        'maxPixels': 1E12,\n",
    "    }\n",
    "    rr_count_params = {\n",
    "        'reducer': ee.Reducer.count().unweighted(),\n",
    "        'geometry': qa_img.geometry(), \n",
    "        'crs': qa_img.projection().crs(), \n",
    "        'crsTransform': [30, 0, 15, 0, -30, 15],\n",
    "        'bestEffort': False,\n",
    "        'maxPixels': 1E12,\n",
    "    }\n",
    "    \n",
    "    tile_scale = 1\n",
    "    if tile_scale != 1:\n",
    "        rr_mean_params['tileScale'] = tile_scale\n",
    "        rr_count_params['tileScale'] = tile_scale\n",
    "\n",
    "    refl_sr_nomask_bands = (\n",
    "        landsat_img.select(['SR_RED', 'SR_GREEN', 'SR_BLUE'])\n",
    "        .multiply([0.0000275]).add([-0.2]).clamp(0, 1)\n",
    "    )\n",
    "    refl_sr_masked_bands = (\n",
    "        landsat_img.select(\n",
    "            ['SR_RED', 'SR_GREEN', 'SR_BLUE'], \n",
    "            ['UNMASKED_SR_RED', 'UNMASKED_SR_GREEN', 'UNMASKED_SR_BLUE']\n",
    "        )\n",
    "        .multiply([0.0000275]).add([-0.2]).clamp(0, 1)\n",
    "        .updateMask(fmask_update_mask)\n",
    "    )\n",
    "    refl_toa_nomask_bands = (\n",
    "        landsat_toa_img.select(\n",
    "            refl_toa_bands_dict.get(landsat_type), \n",
    "            ['TOA_RED', 'TOA_GREEN', 'TOA_BLUE']\n",
    "        )\n",
    "    )\n",
    "    refl_toa_masked_bands = (\n",
    "        landsat_toa_img.select(\n",
    "            refl_toa_bands_dict.get(landsat_type), \n",
    "            ['UNMASKED_TOA_RED', 'UNMASKED_TOA_GREEN', 'UNMASKED_TOA_BLUE']\n",
    "        )\n",
    "        .updateMask(fmask_update_mask)\n",
    "    )\n",
    "    refl_mean_stats = (\n",
    "        refl_sr_nomask_bands\n",
    "        .addBands(refl_sr_masked_bands)\n",
    "        .addBands(refl_toa_nomask_bands)\n",
    "        .addBands(refl_toa_masked_bands)\n",
    "        .updateMask(land_mask)\n",
    "        .reduceRegion(**rr_mean_params)\n",
    "    )\n",
    "\n",
    "    # Compute the masked count stats (these may be the same, not sure yet)\n",
    "    # If they are, then it may make more sense to compute the masked and unmasked count\n",
    "    count_stats = (\n",
    "        landsat_img.select(['SR_RED'], ['UNMASKED_PIXELS']).updateMask(fmask_update_mask)\n",
    "        .addBands([\n",
    "            landsat_img.select(['SR_RED'], ['TOTAL_PIXELS']),\n",
    "            cloud_mask.selfMask().rename(['CLOUD_PIXELS']),\n",
    "            cirrus_mask.selfMask().rename(['CIRRUS_PIXELS']),\n",
    "            dilate_mask.selfMask().rename(['DILATE_PIXELS']),\n",
    "            shadow_mask.selfMask().rename(['SHADOW_PIXELS']),\n",
    "            snow_mask.selfMask().rename(['SNOW_PIXELS']),\n",
    "            water_mask.selfMask().rename(['WATER_PIXELS']),\n",
    "            saturated_mask.selfMask().rename(['SATURATED_PIXELS']),\n",
    "            acca_mask.selfMask().rename(['ACCA_PIXELS']),\n",
    "        ])\n",
    "        .updateMask(land_mask)\n",
    "        .reduceRegion(**rr_count_params)\n",
    "    )\n",
    "\n",
    "    # # Compute the SSEBop ETf stats\n",
    "    # ssebop_stats = (\n",
    "    #     ee.Image(landsat_img).select('SSEBOP_ETF').divide(10000)\n",
    "    #     .updateMask(land_mask)\n",
    "    #     .reduceRegion(\n",
    "    #         reducer=ee.Reducer.mean().unweighted()\n",
    "    #             .combine(ee.Reducer.count().unweighted(), '', True)\n",
    "    #             # .setOutputs(['SSEBOP_ETF_MEAN', 'SSEBOP_ETF_COUNT'])\n",
    "    #         ,\n",
    "    #         geometry=qa_img.geometry(), \n",
    "    #         crs=qa_img.projection().crs(), \n",
    "    #         crsTransform=[30, 0, 15, 0, -30, 15],\n",
    "    #         bestEffort=False,\n",
    "    #         maxPixels=1E10,\n",
    "    #     )\n",
    "    # )\n",
    "\n",
    "    # # Compute the grid stats for the default cloud mask\n",
    "    # mask_img = fmask_mask.updateMask(land_mask)\n",
    "    # # image_url = (\n",
    "    # #     grid_mask_img.visualize(min=0, max=1, palette=['orange', 'blue'])\n",
    "    # #     .getThumbURL({'region': mask_img.geometry().bounds(1, 'EPSG:4326'), 'dimensions': 1024})\n",
    "    # # )\n",
    "    # # ipyplot.plot_images([image_url], img_width=1024)\n",
    "\n",
    "    # # First build the covering grid\n",
    "    # # 30, 60, 120, 240, 480, 960, 1920, 3840, 7680, 15360, 30720, 61140, 122880\n",
    "    # grid_coll = covering_grid(qa_img, 7680)\n",
    "    # # grid_coll = qa_img.geometry().coveringGrid(qa_img.projection().crs(), 7680)\n",
    "    # # grid_coll = qa_img.geometry().coveringGrid(qa_img.projection().crs(), 15360)\n",
    "\n",
    "    # # Compute the scene percent cloud\n",
    "    # # We may already have this value in this function but recompute for now\n",
    "    # image_masked_pct = ee.Number(mask_img.rename('masked_pct').reduceRegion(**rr_mean_params).get('masked_pct'))\n",
    "    # #print(image_cloud_pct.getInfo())\n",
    "    \n",
    "    # # Then compute the stats for each grid cell\n",
    "    # def grid_stats_func(ftr):\n",
    "    #     stats = mask_img.addBands(mask_img.mask()).rename(['masked', 'total']).reduceRegion(**{\n",
    "    #         'reducer': ee.Reducer.mean().unweighted(), 'geometry': ftr.geometry(), \n",
    "    #         'crs': qa_img.projection().crs(), 'crsTransform': [30, 0, 15, 0, -30, 15], \n",
    "    #         'bestEffort': False, 'maxPixels': 1E12,\n",
    "    #     })\n",
    "\n",
    "    #     stats = stats.set('masked_dec', ee.Number(stats.get('masked')).multiply(10).round().divide(10))\n",
    "        \n",
    "    #     # Start with a dictionary set to 0 to handle the grid cells that don't intersect the image\n",
    "    #     stats = ee.Dictionary({'masked': 0, 'total': 0}).combine(stats, True)\n",
    "        \n",
    "    #     # Compute the difference in cloudiness from the scene average\n",
    "    #     #stats = stats.set('diff', ee.Number(stats.get('masked')).subtract(image_masked_pct))\n",
    "        \n",
    "    #     return ee.Feature(ftr.geometry(), stats)\n",
    "\n",
    "    # # Only keep grid cells that cover the unmasked portion of the scene by some amount\n",
    "    # min_total = 0.5\n",
    "    # grid_coll = ee.FeatureCollection(grid_coll.map(grid_stats_func)).filter(ee.Filter.gt('total', min_total))\n",
    "    # grid_stats = grid_coll.aggregate_stats('diff')\n",
    "    # grid_histogram\n",
    "    # grid_stats = ee.Dictionary({\n",
    "    #     'GRID_COUNT': grid_stats.get('total_count'),\n",
    "    #     'GRID_MASK_PCT': image_masked_pct,\n",
    "    #     # 'GRID_COUNT': grid_stats.get('valid_count'),\n",
    "    #     # 'GRID_DIFF_MEAN': grid_stats.get('mean'),\n",
    "    #     # 'GRID_DIFF_MIN': grid_stats.get('min'),\n",
    "    #     # 'GRID_DIFF_MAX': grid_stats.get('max'),\n",
    "    #     # 'GRID_DIFF_SD': grid_stats.get('total_sd'),\n",
    "    #     # 'GRID_DIFF_VAR': grid_stats.get('total_var'),\n",
    "    #     # 'GRID_DIFF_SUMSQ': grid_stats.get('sum_sq'),\n",
    "    # })\n",
    "\n",
    "    output_stats = (\n",
    "        default_stats\n",
    "        .combine(refl_mean_stats, overwrite=True)\n",
    "        .combine(count_stats, overwrite=True)\n",
    "    )\n",
    "    \n",
    "    return ee.Feature(None, output_stats)\n",
    "\n",
    "\n",
    "# image_id = 'LANDSAT/LC08/C02/T1_L2/LC08_019037_20200911'  # random\n",
    "# # image_id = 'LANDSAT/LC09/C02/T1_L2/LC09_023034_20220703'  # clustered\n",
    "# # image_id = 'LANDSAT/LC09/C02/T1_L2/LC09_029027_20240328'  # clustered\n",
    "# test_img = (\n",
    "#     ee.Image(image_id)\n",
    "#     .select(refl_sr_bands_dict.get('LE07'), ['SR_RED', 'SR_GREEN', 'SR_BLUE', 'QA_PIXEL', 'QA_RADSAT'])\n",
    "#     .set('scene_id', image_id.split('/')[-1])\n",
    "#     .set('landsat_toa_img', ee.Image(image_id.replace('T1_L2', 'T1_TOA')))\n",
    "# )\n",
    "# output = image_stats(test_img)\n",
    "# pprint.pprint(output.getInfo())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a68145-1535-4174-b3ba-72832bbee0c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fc6820-c77b-4a4d-878f-ed7082256a53",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute stats and save CSV to bucket\n",
    "#start_year = 1984\n",
    "#end_year = 2023\n",
    "start_year = 2024\n",
    "end_year = 2025\n",
    "years = list(range(start_year, end_year+1))\n",
    "delay = 1\n",
    "\n",
    "overwrite_flag = True\n",
    "local_files = os.listdir(stats_ws)\n",
    "\n",
    "print('\\nIterating by year and wrs2')             \n",
    "for year in years: \n",
    "    \n",
    "    print(f'{year} - reading bucket files')\n",
    "    bucket_object = storage_client.get_bucket(BUCKET_NAME)\n",
    "    bucket_files = {os.path.basename(x.name) for x in bucket_object.list_blobs(prefix=f'{BUCKET_FOLDER}/{year}')}\n",
    "\n",
    "    start_date = ee.Date.fromYMD(year, 1, 1)\n",
    "    end_date = start_date.advance(1, 'year')\n",
    "        \n",
    "    for wrs2_tile in wrs2_list:\n",
    "        \n",
    "        # if wrs2_skip_list and wrs2_tile in wrs2_skip_list:\n",
    "        #     # print(f'{wrs2_tile} - wrs2 in skip list exists, skipping')\n",
    "        #     continue\n",
    "        # if int(wrs2_tile[1:4]) != 20:\n",
    "        #     continue\n",
    "        # if int(wrs2_tile[1:4]) not in range(10, 45):\n",
    "        #     continue\n",
    "\n",
    "        if f'{wrs2_tile}_{year}.csv' in bucket_files:\n",
    "            if not overwrite_flag:\n",
    "                # print(f'{wrs2_tile} - bucket csv exists and overwrite is False, skipping')\n",
    "                continue\n",
    "            else:\n",
    "                print(f'  removing csv from bucket')\n",
    "                blob = bucket_object.blob(f'{BUCKET_FOLDER}/{year}/{wrs2_tile}_{year}.csv')\n",
    "                blob.delete() \n",
    "        # # I'm not sure that checking the local file is all that helpful \n",
    "        # if (f'{wrs2_tile}_{year}.csv' in stats_files) and not overwrite_flag:\n",
    "        #     # print(f'{wrs2_tile} - local csv exists and overwrite is False, skipping')\n",
    "        #     continue\n",
    "        \n",
    "        print(f'{wrs2_tile}')\n",
    "        \n",
    "        l4_sr_coll = (\n",
    "            ee.ImageCollection('LANDSAT/LT04/C02/T1_L2')\n",
    "            .filterDate(start_date, end_date)\n",
    "            .filterMetadata('WRS_PATH', 'equals', int(wrs2_tile[1:4]))\n",
    "            .filterMetadata('WRS_ROW', 'equals', int(wrs2_tile[5:8]))\n",
    "            .select(refl_sr_bands_dict.get('LT04'), refl_sr_bands)\n",
    "            .map(lambda img: img.set({'scene_id': img.get('system:index')}))\n",
    "            # .map(lambda img: img.set('image_id', img.get('system:id')))\n",
    "        )\n",
    "        l5_sr_coll = (\n",
    "            ee.ImageCollection('LANDSAT/LT05/C02/T1_L2')\n",
    "            .filterDate(start_date, end_date)\n",
    "            .filterMetadata('WRS_PATH', 'equals', int(wrs2_tile[1:4]))\n",
    "            .filterMetadata('WRS_ROW', 'equals', int(wrs2_tile[5:8]))\n",
    "            .select(refl_sr_bands_dict.get('LT05'), refl_sr_bands)\n",
    "            .map(lambda img: img.set({'scene_id': img.get('system:index')}))\n",
    "            # .map(lambda img: img.set('image_id', img.get('system:id')))\n",
    "        )\n",
    "        l7_sr_coll = (\n",
    "            ee.ImageCollection('LANDSAT/LE07/C02/T1_L2')\n",
    "            .filterDate(start_date, end_date)\n",
    "            .filterMetadata('WRS_PATH', 'equals', int(wrs2_tile[1:4]))\n",
    "            .filterMetadata('WRS_ROW', 'equals', int(wrs2_tile[5:8]))\n",
    "            .select(refl_sr_bands_dict.get('LE07'), refl_sr_bands)\n",
    "            .map(lambda img: img.set({'scene_id': img.get('system:index')}))\n",
    "            # .map(lambda img: img.set('image_id', img.get('system:id')))\n",
    "        )\n",
    "        l8_sr_coll = (\n",
    "            ee.ImageCollection('LANDSAT/LC08/C02/T1_L2')\n",
    "            .filterDate(start_date, end_date)\n",
    "            .filterMetadata('WRS_PATH', 'equals', int(wrs2_tile[1:4]))\n",
    "            .filterMetadata('WRS_ROW', 'equals', int(wrs2_tile[5:8]))\n",
    "            .select(refl_sr_bands_dict.get('LC08'), refl_sr_bands)\n",
    "            .map(lambda img: img.set({'scene_id': img.get('system:index')}))\n",
    "            # .map(lambda img: img.set('image_id', img.get('system:id')))\n",
    "        )\n",
    "        l9_sr_coll = (\n",
    "            ee.ImageCollection('LANDSAT/LC09/C02/T1_L2')\n",
    "            .filterDate(start_date, end_date)\n",
    "            .filterMetadata('WRS_PATH', 'equals', int(wrs2_tile[1:4]))\n",
    "            .filterMetadata('WRS_ROW', 'equals', int(wrs2_tile[5:8]))\n",
    "            .select(refl_sr_bands_dict.get('LC09'), refl_sr_bands)\n",
    "            .map(lambda img: img.set({'scene_id': img.get('system:index')}))\n",
    "            # .map(lambda img: img.set('image_id', img.get('system:id')))\n",
    "        )\n",
    "        if year < 1993:\n",
    "            landsat_sr_coll = l5_sr_coll.merge(l4_sr_coll)\n",
    "        elif year in range(1993, 1999):\n",
    "            landsat_sr_coll = l5_sr_coll\n",
    "        elif year in range(1999, 2013):\n",
    "            landsat_sr_coll = l5_sr_coll.merge(l7_sr_coll)\n",
    "        elif year in range(2013, 2023):\n",
    "            landsat_sr_coll = l8_sr_coll.merge(l7_sr_coll)\n",
    "        elif year >= 2023:\n",
    "            landsat_sr_coll = l9_sr_coll.merge(l8_sr_coll)\n",
    "\n",
    "        if landsat_sr_coll.size().getInfo() == 0:\n",
    "            print('  no landsat sr images in year/tile')\n",
    "            continue\n",
    "\n",
    "        l4_toa_coll = (\n",
    "            ee.ImageCollection('LANDSAT/LT04/C02/T1_TOA')\n",
    "            .filterDate(start_date, end_date)\n",
    "            .filterMetadata('WRS_PATH', 'equals', int(wrs2_tile[1:4]))\n",
    "            .filterMetadata('WRS_ROW', 'equals', int(wrs2_tile[5:8]))\n",
    "            .map(lambda img: img.set({'scene_id': img.get('system:index')}))\n",
    "            # .map(lambda img: img.set('image_id', img.get('system:id')))\n",
    "        )\n",
    "        l5_toa_coll = (\n",
    "            ee.ImageCollection('LANDSAT/LT05/C02/T1_TOA')\n",
    "            .filterDate(start_date, end_date)\n",
    "            .filterMetadata('WRS_PATH', 'equals', int(wrs2_tile[1:4]))\n",
    "            .filterMetadata('WRS_ROW', 'equals', int(wrs2_tile[5:8]))\n",
    "            .map(lambda img: img.set({'scene_id': img.get('system:index')}))\n",
    "            # .map(lambda img: img.set('image_id', img.get('system:id')))\n",
    "        )\n",
    "        l7_toa_coll = (\n",
    "            ee.ImageCollection('LANDSAT/LE07/C02/T1_TOA')\n",
    "            .filterDate(start_date, end_date)\n",
    "            .filterMetadata('WRS_PATH', 'equals', int(wrs2_tile[1:4]))\n",
    "            .filterMetadata('WRS_ROW', 'equals', int(wrs2_tile[5:8]))\n",
    "            .map(lambda img: img.set({'scene_id': img.get('system:index')}))\n",
    "            # .map(lambda img: img.set('image_id', img.get('system:id')))\n",
    "        )\n",
    "        l8_toa_coll = (\n",
    "            ee.ImageCollection('LANDSAT/LC08/C02/T1_TOA')\n",
    "            .filterDate(start_date, end_date)\n",
    "            .filterMetadata('WRS_PATH', 'equals', int(wrs2_tile[1:4]))\n",
    "            .filterMetadata('WRS_ROW', 'equals', int(wrs2_tile[5:8]))\n",
    "            .map(lambda img: img.set({'scene_id': img.get('system:index')}))\n",
    "            # .map(lambda img: img.set('image_id', img.get('system:id')))\n",
    "        )\n",
    "        l9_toa_coll = (\n",
    "            ee.ImageCollection('LANDSAT/LC09/C02/T1_TOA')\n",
    "            .filterDate(start_date, end_date)\n",
    "            .filterMetadata('WRS_PATH', 'equals', int(wrs2_tile[1:4]))\n",
    "            .filterMetadata('WRS_ROW', 'equals', int(wrs2_tile[5:8]))\n",
    "            .map(lambda img: img.set({'scene_id': img.get('system:index')}))\n",
    "            # .map(lambda img: img.set('image_id', img.get('system:id')))\n",
    "        )\n",
    "\n",
    "        if year < 1993:\n",
    "            landsat_toa_coll = l5_toa_coll.merge(l4_toa_coll)\n",
    "        elif year in range(1993, 1999):\n",
    "            landsat_toa_coll = l5_toa_coll\n",
    "        elif year in range(1999, 2013):\n",
    "            landsat_toa_coll = l5_toa_coll.merge(l7_toa_coll)\n",
    "        elif year in range(2013, 2023):\n",
    "            landsat_toa_coll = l8_toa_coll.merge(l7_toa_coll)\n",
    "        elif year >= 2023:\n",
    "            landsat_toa_coll = l9_toa_coll.merge(l8_toa_coll)\n",
    "\n",
    "        landsat_coll = ee.Join.saveFirst(matchKey='landsat_toa_img').apply(\n",
    "            landsat_sr_coll, landsat_toa_coll, \n",
    "            ee.Filter.equals(leftField='scene_id', rightField='scene_id'),\n",
    "        )\n",
    "\n",
    "        # CGM - Not computing the SSEBop ETf stats for now\n",
    "        # # if year >= 2016:\n",
    "        # #     ssebop_etf_coll_id = 'projects/openet/assets/ssebop/conus/gridmet/landsat/c02'\n",
    "        # # else:\n",
    "        # #     ssebop_etf_coll_id = 'projects/usgs-gee-nhm-ssebop/assets/ssebop/landsat/c02'\n",
    "        # ssebop_etf_coll_id = 'projects/usgs-gee-nhm-ssebop/assets/ssebop/landsat/c02'\n",
    "        # ssebop_etf_coll = (\n",
    "        #     ee.ImageCollection(ssebop_etf_coll_id)\n",
    "        #     .filterDate(f'{year}-01-01', f'{year+1}-01-01')\n",
    "        #     .filterMetadata('wrs2_tile', 'equals', wrs2_tile)\n",
    "        #     .select(['et_fraction'], ['SSEBOP_ETF'])\n",
    "        # )\n",
    "        # join_coll = ee.ImageCollection(landsat_coll).linkCollection(\n",
    "        #     ssebop_etf_coll, linkedBands=['SSEBOP_ETF'], matchPropertyName='scene_id'\n",
    "        # )\n",
    "        # output_coll = join_coll.map(image_stats)\n",
    "\n",
    "        # Compute the image statistics\n",
    "        output_coll = ee.ImageCollection(landsat_coll).map(image_stats)\n",
    "        \n",
    "        print('  Starting export task')\n",
    "        task = ee.batch.Export.table.toCloudStorage(\n",
    "            output_coll, \n",
    "            f'{wrs2_tile}_{year}_scene_stats', \n",
    "            bucket=BUCKET_NAME, \n",
    "            fileNamePrefix=f'{BUCKET_FOLDER}/{year}/{wrs2_tile}_{year}', \n",
    "        )\n",
    "        task.start()\n",
    "        # print(task.status()['id'])\n",
    "    \n",
    "        time.sleep(delay)\n",
    "\n",
    "print('\\nDone')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b1d7c7-8e97-48a5-aea3-f22025fa25f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778a40db-dbe2-4516-826f-66ef16a42a2c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# # Clean up the CSV files to remove unneeded columns\n",
    "# start_year = 2024\n",
    "# end_year = 2024\n",
    "\n",
    "# for year in range(start_year, end_year + 1):\n",
    "#     print(f'{year}')\n",
    "#     for wrs2_tile in sorted(wrs2_list):        \n",
    "#         wrs2_stats_path = os.path.join(stats_ws, f'{year}', f'{wrs2_tile}_{year}.csv')\n",
    "#         if not os.path.isfile(wrs2_stats_path):\n",
    "#             # print(f'  {wrs2_tile}_{year} - Missing stats CSV, skipping')\n",
    "#             continue\n",
    "#         # print(f'  {wrs2_tile}')\n",
    "            \n",
    "#         try:\n",
    "#             wrs2_stats_df = pd.read_csv(wrs2_stats_path)\n",
    "#             # wrs2_stats_df.reset_index(drop=True, inplace=True)\n",
    "#         except Exception as e:\n",
    "#             print(f'  {wrs2_tile}_{year} - Error reading CSV, skipping')\n",
    "#             continue\n",
    "#         if wrs2_stats_df.empty:\n",
    "#             continue\n",
    "            \n",
    "#         for k in ['system:index', '.geo', 'Unnamed: 0', 'Unnamed: 0.1', 'Unnamed: 0.2', 'Unnamed: 0.3', 'Unnamed: 0.4', 'DATE']:\n",
    "#             try:\n",
    "#                 wrs2_stats_df.drop(columns=[k], inplace=True)\n",
    "#             except:\n",
    "#                 pass\n",
    "#         if any(['unnamed' in c.lower() for c in wrs2_stats_df.columns]):\n",
    "#             print(f'{wrs2_tile}_{year}.csv')\n",
    "#             print(wrs2_stats_df.columns)\n",
    "#             input('ENTER')\n",
    "\n",
    "#         # if 'DATE' not in wrs2_stats_df.columns:\n",
    "#         #     wrs2_stats_df['DATE'] = wrs2_stats_df['SCENE_ID'].str.slice(12, 20)\n",
    "#         if 'WRS2' not in wrs2_stats_df.columns:\n",
    "#             wrs2_stats_df['WRS2'] = 'p' + wrs2_stats_df['SCENE_ID'].str.slice(5, 8) + 'r' + wrs2_stats_df['SCENE_ID'].str.slice(8, 11)\n",
    "\n",
    "#         # Force the Moran columns to a float type\n",
    "#         for k in ['MORAN_1K', 'MORAN_2K', 'MORAN_4K', 'MORAN_8K']:\n",
    "#             if wrs2_stats_df[k].dtype == 'int64':\n",
    "#                 wrs2_stats_df[k] = wrs2_stats_df[k].astype(float)\n",
    "            \n",
    "#         # print(f'  {wrs2_stats_path.split(\"/\")[-1]}')\n",
    "#         wrs2_stats_df.to_csv(wrs2_stats_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a01253e-6612-4099-ac01-5478ec797c9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64d315b-5971-48d0-9252-94bf95054a66",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# # \n",
    "# def cloud_mask_func(landsat_img):\n",
    "#     scene_id = ee.String(ee.Image(landsat_img).get('scene_id'))\n",
    "#     print(scene_id.getInfo())\n",
    "#     landsat_type = scene_id.slice(0, 4)\n",
    "    \n",
    "#     default_stats = ee.Dictionary({\n",
    "#         'MASKED_COUNT': -1, 'NOMASK_COUNT': -1,\n",
    "#         'SR_NOMASK_RED': -1, 'SR_NOMASK_GREEN': -1, 'SR_NOMASK_BLUE': -1,\n",
    "#         'SR_MASKED_RED': -1, 'SR_MASKED_GREEN': -1, 'SR_MASKED_BLUE': -1,\n",
    "#         'CLOUD_COVER_LAND': landsat_img.get('CLOUD_COVER_LAND'),  \n",
    "#         'SCENE_ID': scene_id,\n",
    "#     })\n",
    "\n",
    "#     # Get the cloud mask (including the snow mask for now)\n",
    "#     qa_img = ee.Image(landsat_img.select(['QA_PIXEL']))\n",
    "#     cloud_mask = qa_img.rightShift(3).bitwiseAnd(1).neq(0)\n",
    "    \n",
    "#     # if cirrus_flag:\n",
    "#     cirrus_mask = qa_img.rightShift(2).bitwiseAnd(1).neq(0)\n",
    "#     cloud_mask = cloud_mask.Or(cirrus_mask)\n",
    "    \n",
    "#     # if dilate_flag:\n",
    "#     dilate_mask = qa_img.rightShift(1).bitwiseAnd(1).neq(0)\n",
    "#     cloud_mask = cloud_mask.Or(dilate_mask)\n",
    "\n",
    "#     # if shadow_flag:\n",
    "#     shadow_mask = qa_img.rightShift(4).bitwiseAnd(1).neq(0)\n",
    "#     cloud_mask = cloud_mask.Or(shadow_mask)\n",
    "    \n",
    "#     # if snow_flag:\n",
    "#     snow_mask = qa_img.rightShift(5).bitwiseAnd(1).neq(0)\n",
    "#     cloud_mask = cloud_mask.Or(snow_mask)\n",
    "\n",
    "#     # if water_flag:\n",
    "#     # water_mask = qa_img.rightShift(7).bitwiseAnd(1).neq(0)\n",
    "#     # cloud_mask = cloud_mask.Or(water_mask)\n",
    "    \n",
    "#     # if saturated_flag:\n",
    "#     #     # Masking if saturated in any band\n",
    "#     #     sat_mask = input_img.select(['QA_RADSAT']).gt(0)\n",
    "#     #     cloud_mask = cloud_mask.Or(sat_mask)\n",
    "\n",
    "#     # # Apply a small erosion/dilation\n",
    "#     # cloud_mask = (\n",
    "#     #     cloud_mask\n",
    "#     #     .reduceNeighborhood(ee.Reducer.min(), ee.Kernel.circle(radius=30, units='meters'))\n",
    "#     #     .reduceNeighborhood(ee.Reducer.max(), ee.Kernel.circle(radius=120, units='meters'))\n",
    "#     #     # .reduceNeighborhood(ee.Reducer.min(), ee.Kernel.circle(radius=1, units='pixels'))\n",
    "#     #     # .reduceNeighborhood(ee.Reducer.max(), ee.Kernel.circle(radius=2, units='pixels'))\n",
    "#     #     # .reproject(qa_img.projection())\n",
    "#     # )\n",
    "\n",
    "#     # Flip to set cloudy pixels to 0 and clear to 1\n",
    "#     cloud_mask = cloud_mask.Not()       \n",
    "\n",
    "#     return cloud_mask\n",
    "\n",
    "\n",
    "# refl_sr_bands_dict = ee.Dictionary({\n",
    "#     'LT05': ['SR_B3', 'SR_B2', 'SR_B1', 'QA_PIXEL'],\n",
    "#     'LE07': ['SR_B3', 'SR_B2', 'SR_B1', 'QA_PIXEL'],\n",
    "#     'LC08': ['SR_B4', 'SR_B3', 'SR_B2', 'QA_PIXEL'],\n",
    "#     'LC09': ['SR_B4', 'SR_B3', 'SR_B2', 'QA_PIXEL'],\n",
    "# })\n",
    "\n",
    "\n",
    "# wrs2_tile = 'p048r027'\n",
    "# year = 2024\n",
    "\n",
    "# # l8_sr_coll = (\n",
    "# # landsat_coll = (\n",
    "# #     ee.ImageCollection('LANDSAT/LC08/C02/T1_L2')\n",
    "# #     .filterDate(f'{year}-02-01', f'{year+1}-01-01')\n",
    "# #     .filterMetadata('WRS_PATH', 'equals', int(wrs2_tile[1:4]))\n",
    "# #     .filterMetadata('WRS_ROW', 'equals', int(wrs2_tile[5:8]))\n",
    "# #     .select(refl_sr_bands_dict.get('LC08'), ['SR_RED', 'SR_GREEN', 'SR_BLUE', 'QA_PIXEL'])\n",
    "# #     .map(lambda img: img.set('scene_id', img.get('system:index')))\n",
    "# # )\n",
    "# # l9_sr_coll = (\n",
    "# landsat_coll = (\n",
    "#     ee.ImageCollection('LANDSAT/LC09/C02/T1_L2')\n",
    "#     .filterDate(f'{year}-02-01', f'{year+1}-01-01')\n",
    "#     .filterMetadata('WRS_PATH', 'equals', int(wrs2_tile[1:4]))\n",
    "#     .filterMetadata('WRS_ROW', 'equals', int(wrs2_tile[5:8]))\n",
    "#     .select(refl_sr_bands_dict.get('LC09'), ['SR_RED', 'SR_GREEN', 'SR_BLUE', 'QA_PIXEL'])\n",
    "#     .map(lambda img: img.set('scene_id', img.get('system:index')))\n",
    "# )\n",
    "# # landsat_coll = l9_sr_coll.merge(l8_sr_coll)\n",
    "\n",
    "# test_img = ee.Image(landsat_coll.first())\n",
    "# output_img = cloud_mask_func(test_img)\n",
    "\n",
    "# landsat_region = test_img.select([0]).geometry().bounds(1, 'EPSG:4326')\n",
    "# image_size = 768\n",
    "\n",
    "# image_url = (\n",
    "#     test_img.select(['SR_RED', 'SR_GREEN', 'SR_BLUE']).multiply([0.0000275, 0.0000275, 0.0000275]).add([-0.2, -0.2, -0.2])\n",
    "#     .where(land_mask.unmask().eq(0), 0.25)\n",
    "#     .getThumbURL({'min': 0.0, 'max': 0.30, 'region': landsat_region, 'dimensions': image_size})\n",
    "# )\n",
    "# output_url = (\n",
    "#     ee.Image(output_img)\n",
    "#     .where(land_mask.unmask().eq(0), 0.80)\n",
    "#     .getThumbURL({'min': 0, 'max': 1, 'region': landsat_region, 'dimensions': image_size})\n",
    "# )\n",
    "\n",
    "# ipyplot.plot_images([image_url, output_url], img_width=image_size)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
