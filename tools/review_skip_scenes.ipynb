{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08685d7a-ac12-4166-812a-f3e27a9d7e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import os\n",
    "import pprint\n",
    "\n",
    "import ee\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import Image, display\n",
    "import ipyplot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed596c3c-b5d0-489d-9fd7-ef3598f9e813",
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Initialize(\n",
    "    project='ee-cmorton',\n",
    "    opt_url='https://earthengine-highvolume.googleapis.com'\n",
    ")\n",
    "\n",
    "stats_ws = os.path.join(os.getcwd(), 'stats')\n",
    "if not os.path.isdir(stats_ws):\n",
    "    os.makedirs(stats_ws)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea736ef9-694c-4a41-bc1e-e00d3e5c7485",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrs2_skip_list = [\n",
    "    'p010r027', 'p010r030'\n",
    "]\n",
    "\n",
    "wrs2_list = sorted(\n",
    "    ee.FeatureCollection('projects/openet/assets/features/wrs2/custom')\n",
    "    .filterBounds(ee.Geometry.BBox(-124, 26, -68, 50))\n",
    "    .filter(ee.Filter.inList('mgrs_tile', wrs2_skip_list).Not())\n",
    "    .aggregate_histogram('wrs2_tile').keys().getInfo(),\n",
    "    reverse=True\n",
    ")\n",
    "print(len(wrs2_list))\n",
    "\n",
    "\n",
    "ocean_wrs2_list = [\n",
    "    'p048r027', 'p047r031', 'p047r030', 'p046r033', 'p045r034', \n",
    "    'p044r035', 'p043r036', 'p041r037', 'p040r038', \n",
    "    'p024r040', 'p024r027', 'p023r040', 'p023r027', 'p020r029',\n",
    "    'p017r041', 'p016r038', 'p015r040', 'p015r037', \n",
    "    'p013r033', 'p012r032', 'p011r031', 'p011r030', \n",
    "]\n",
    "\n",
    "ocean_wrs2_list = [\n",
    "    'p048r027', 'p047r031', 'p047r030', 'p047r029', 'p046r033', \n",
    "    'p045r034', 'p044r035', 'p043r036', 'p041r037', 'p040r038', \n",
    "    'p025r040', 'p024r040', 'p024r027', 'p023r040', \n",
    "    'p023r027', 'p022r040', 'p021r040','p020r029',\n",
    "    'p017r041', 'p016r038', 'p015r040', 'p015r037', \n",
    "    'p013r033', 'p012r032', 'p011r031', 'p011r030', \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b4bed5-252d-4243-b7f8-87c2b3751395",
   "metadata": {},
   "outputs": [],
   "source": [
    "land_mask = ee.Image('projects/openet/assets/features/water_mask').Not()\n",
    "# Apply the NLCD/NALCMS water mask (anywhere it is water, set the ocean mask \n",
    "land_mask = land_mask.where(ee.Image(\"USGS/NLCD_RELEASES/2020_REL/NALCMS\").unmask(18).eq(18), 0)\n",
    "# land_mask = land_mask.And(ee.Image(\"USGS/NLCD_RELEASES/2020_REL/NALCMS\").unmask(18).neq(18))\n",
    "# # land_mask = ee.Image('projects/openet/assets/meteorology/conus404/ancillary/land_mask')\n",
    "\n",
    "# etf_coll_id = 'projects/openet/assets/ssebop/conus/gridmet/landsat/c02'\n",
    "etf_coll_id = 'projects/usgs-gee-nhm-ssebop/assets/ssebop/landsat/c02'\n",
    "# etf_coll_id = 'projects/openet/assets/intercomparison/ssebop/landsat/c02/v0p2p6'\n",
    "band_name = 'et_fraction'\n",
    "\n",
    "rgb_bands = {\n",
    "    'LT04': ['SR_B3', 'SR_B2', 'SR_B1'],\n",
    "    'LT05': ['SR_B3', 'SR_B2', 'SR_B1'],\n",
    "    'LE07': ['SR_B3', 'SR_B2', 'SR_B1'],\n",
    "    'LC08': ['SR_B4', 'SR_B3', 'SR_B2'],\n",
    "    'LC09': ['SR_B4', 'SR_B3', 'SR_B2'],\n",
    "}\n",
    "\n",
    "# 0 - white, 1 - no fill (green), 2 - shadow (dark blue), 3 - snow (light blue), 4 - cloud (light gray), 5 - water (purple), 6 - ocean mask\n",
    "fmask_palette = \"ffffff, 9effa1, blue, 00aff2, dddddd, purple, bfbfbf\"\n",
    "fmask_max = 6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438adba8-726a-40af-b642-f9e1a9ef4ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of WRS2 tiles from the SSEBop collection\n",
    "wrs2_list = sorted(\n",
    "    ee.ImageCollection(etf_coll_id).filterDate('2020-01-01', '2024-01-01')\n",
    "    .aggregate_histogram('wrs2_tile').keys().getInfo(),\n",
    "    reverse=True\n",
    ")\n",
    "wrs2_list = wrs2_list + ['p018r028']\n",
    "# pprint.pprint(wrs2_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bace06-5954-4218-a205-8a9d959d47e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fmask(landsat_img):\n",
    "    # Add the fmask image on top of the true color image\n",
    "    qa_img = landsat_img.select('QA_PIXEL')\n",
    "    fill_mask = qa_img.bitwiseAnd(1).neq(0)                  # bits: 0\n",
    "    dilate_mask = qa_img.rightShift(1).bitwiseAnd(1).neq(0)  # bits: 1\n",
    "    cirrus_mask = qa_img.rightShift(2).bitwiseAnd(1).neq(0)  # bits: 2\n",
    "    cloud_mask = qa_img.rightShift(3).bitwiseAnd(1).neq(0)   # bits: 3\n",
    "    shadow_mask = qa_img.rightShift(4).bitwiseAnd(1).neq(0)  # bits: 4\n",
    "    snow_mask = qa_img.rightShift(5).bitwiseAnd(1).neq(0)    # bits: 5\n",
    "    clear_mask = qa_img.rightShift(6).bitwiseAnd(1).neq(0)   # bits: 6\n",
    "    water_mask = qa_img.rightShift(7).bitwiseAnd(1).neq(0)   # bits: 7\n",
    "    # cloud_conf = qa_img.rightShift(8).bitwiseAnd(3)          # bits: 8, 9\n",
    "    # shadow_conf = qa_img.rightShift(10).bitwiseAnd(3)        # bits: 10, 11\n",
    "    # snow_conf = qa_img.rightShift(12).bitwiseAnd(3)          # bits: 12, 13\n",
    "    # cirrus_conf = qa_img.rightShift(14).bitwiseAnd(3)        # bits: 14, 15\n",
    "\n",
    "    # Saturated pixels\n",
    "    # Flag as saturated if any of the RGB bands are saturated\n",
    "    #   or change .gt(0) to .gt(7) to flag if all RGB bands are saturated\n",
    "    # Comment out rightShift line to flag if saturated in any band\n",
    "    bitshift = ee.Dictionary({'LANDSAT_4': 0, 'LANDSAT_5': 0, 'LANDSAT_7': 0, 'LANDSAT_8': 1, 'LANDSAT_9': 1});\n",
    "    saturated_mask = (\n",
    "        landsat_img.select('QA_RADSAT')\n",
    "        .rightShift(ee.Number(bitshift.get(ee.String(landsat_img.get('SPACECRAFT_ID'))))).bitwiseAnd(7)\n",
    "        .gt(0)\n",
    "    )\n",
    "    \n",
    "    # Old \"Fmask\" style image\n",
    "    fmask_img = (\n",
    "        qa_img.multiply(0)\n",
    "        .where(landsat_img.select(['SR_B4']).mask().eq(0), 1)\n",
    "        # .where(saturated_mask, 6)\n",
    "        .where(water_mask, 5)\n",
    "        .where(shadow_mask, 2)\n",
    "        .where(snow_mask, 3)\n",
    "        .where(cloud_mask.Or(dilate_mask).Or(cirrus_mask), 4)\n",
    "        # .add(shadow_mask.multiply(2))\n",
    "        # .add(snow_mask.multiply(3))\n",
    "        # .add(cloud_mask.Or(dilate_mask).Or(cirrus_mask).multiply(4))\n",
    "        # .add(cloud_mask.Or(dilate_mask).multiply(4))\n",
    "        # .add(cloud_mask.And(cloud_conf).multiply(4))\n",
    "        # .add(water_mask.multiply(5))\n",
    "    )\n",
    "    \n",
    "    return fmask_img.updateMask(fmask_img.neq(0)).rename(['fmask'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60efd1c2-b0ec-49d9-94fb-036e32c69254",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4137ebae-6659-46be-92b3-70f276efe40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Print scenes with low pixel count ratios (few unmasked pixels)\n",
    "count_threshold_pct_min = 0\n",
    "count_threshold_pct_max = 101\n",
    "# count_threshold = 1\n",
    "\n",
    "start_year = 1984\n",
    "end_year = 2024\n",
    "years = list(range(start_year, end_year + 1))\n",
    "\n",
    "print_count = 100\n",
    "image_size = 750\n",
    "# image_size = 900\n",
    "# image_size = 1024\n",
    "\n",
    "# Read in the scene skip list\n",
    "scene_skip_url = '../v2p1.csv'\n",
    "# scene_skip_url = 'https://raw.githubusercontent.com/cgmorton/scene-skip-list/main/v2p1.csv'\n",
    "scene_skip_df = pd.read_csv(scene_skip_url)\n",
    "scene_skip_list = list(scene_skip_df['SCENE_ID'].values)\n",
    "print(f'Skip list images: {len(scene_skip_list)}')\n",
    "\n",
    "# scene_cloudscore_url = '../v2p1_cloudscore.csv'\n",
    "# # scene_cloudscore_url = 'https://raw.githubusercontent.com/cgmorton/scene-skip-list/main/v2p1_cloudscore.csv'\n",
    "# scene_cloudscore_list = list(pd.read_csv(scene_cloudscore_url)['SCENE_ID'].values)\n",
    "# print(f'Skip cloudscore images: {len(scene_cloudscore_list)}')\n",
    "\n",
    "\n",
    "red_band = 'SR_RED'\n",
    "green_band = 'SR_GREEN'\n",
    "blue_band = 'SR_BLUE'\n",
    "\n",
    "\n",
    "print('Reading image stats CSV files')\n",
    "stats_df_list = []\n",
    "for wrs2_tile in wrs2_list:\n",
    "    # if int(wrs2_tile[1:4]) not in range(10, 25):\n",
    "    #     continue\n",
    "        \n",
    "    for year in range(start_year, end_year + 1):\n",
    "        wrs2_stats_path = os.path.join(stats_ws, f'{year}', f'{wrs2_tile}_{year}.csv')\n",
    "        if not os.path.isfile(wrs2_stats_path):\n",
    "            # print(f'  {wrs2_tile}_{year} - Missing stats CSV, skipping')\n",
    "            continue\n",
    "        try:\n",
    "            wrs2_stats_df = pd.read_csv(wrs2_stats_path, index_col=False)\n",
    "        except Exception as e:\n",
    "            print(f'  {wrs2_tile}_{year} - Error reading CSV, skipping')\n",
    "            continue\n",
    "        if wrs2_stats_df.empty:\n",
    "            continue\n",
    "        wrs2_stats_df['DATE'] = wrs2_stats_df['SCENE_ID'].str.slice(12, 20)\n",
    "        wrs2_stats_df['WRS2'] = 'p' + wrs2_stats_df['SCENE_ID'].str.slice(5, 8) + 'r' + wrs2_stats_df['SCENE_ID'].str.slice(8, 11)\n",
    "        stats_df_list.append(wrs2_stats_df)\n",
    "\n",
    "stats_df = pd.concat(stats_df_list)\n",
    "\n",
    "\n",
    "# Compute the ratios\n",
    "# stats_df['ACCA_COUNT_RATIO'] = stats_df['ACCA_PIXELS'] / stats_df['TOTAL_PIXELS']\n",
    "stats_df['SNOW_COUNT_RATIO'] = stats_df['SNOW_PIXELS'] / stats_df['TOTAL_PIXELS']\n",
    "# stats_df['SHADOW_COUNT_RATIO'] = stats_df['SHADOW_PIXELS'] / stats_df['TOTAL_PIXELS']\n",
    "stats_df['WATER_COUNT_RATIO'] = stats_df['WATER_PIXELS'] / stats_df['TOTAL_PIXELS']\n",
    "stats_df['MASKED_PIXELS'] = (\n",
    "    stats_df['CLOUD_PIXELS'] + stats_df['CIRRUS_PIXELS'] + stats_df['DILATE_PIXELS']\n",
    "    + stats_df['SHADOW_PIXELS']\n",
    "    + stats_df['SNOW_PIXELS']\n",
    "    # + stats_df['WATER_PIXELS']\n",
    "    + stats_df['ACCA_PIXELS']\n",
    "    # + stats_df['SATURATED_PIXELS']\n",
    ")\n",
    "stats_df['CLOUD_COUNT_RATIO'] = stats_df['MASKED_PIXELS'] / stats_df['TOTAL_PIXELS']\n",
    "# stats_df['CLOUD_COUNT_RATIO'] = stats_df['UNMASKED_PIXELS'] / stats_df['TOTAL_PIXELS']\n",
    "\n",
    "print(f'  {len(stats_df.count(axis=1))}')\n",
    "\n",
    "\n",
    "# Get the subset of target skipped scenes to review\n",
    "subset_df = stats_df[stats_df['SCENE_ID'].isin(scene_skip_list)].copy()\n",
    "# subset_df = stats_df[~stats_df['SCENE_ID'].isin(scene_skip_list)].copy()\n",
    "# subset_df = stats_df[stats_df['SCENE_ID'].isin(scene_cloudscore_list)]\n",
    "\n",
    "# Only look at Landsat 8 and 9 for this review\n",
    "#subset_df = subset_df[subset_df['SCENE_ID'].str.slice(0,4).isin(['LC08', 'LC09'])]\n",
    "\n",
    "# Only look at scenes with a reason of \"Missing\"\n",
    "subset_df = subset_df[subset_df['SCENE_ID'].isin(scene_skip_df[scene_skip_df['REASON'].str.contains('Shadow')]['SCENE_ID'].values)].copy()\n",
    "# subset_df = subset_df[subset_df['SCENE_ID'].isin(scene_skip_df[scene_skip_df['REASON'].str.contains('Snow')]['SCENE_ID'].values)].copy()\n",
    "# subset_df = subset_df[subset_df['SCENE_ID'].isin(scene_skip_df[scene_skip_df['REASON'].str.contains('Missing')]['SCENE_ID'].values)].copy()\n",
    "# subset_df = subset_df[subset_df['SCENE_ID'].isin(scene_skip_df[~scene_skip_df['REASON'].str.contains('Snow')]['SCENE_ID'].values)].copy()\n",
    "\n",
    "# Filter to western scenes in the summer\n",
    "# subset_df = subset_df[subset_df['DATE'].str.slice(4,6).astype(int).isin([4, 5, 6, 7, 8, 9, 10])]\n",
    "# subset_df = subset_df[subset_df['WRS2'].str.slice(1,4).astype(int).isin(range(20, 40))].copy()\n",
    "# subset_df = subset_df[subset_df['WRS2'].str.slice(5,8).astype(int).isin(range(30, 50))].copy()\n",
    "# print(f'  {len(subset_df.count(axis=1))}')\n",
    "\n",
    "# subset_df = subset_df[subset_df['DATE'].str.slice(4,6).astype(int).isin([10])]\n",
    "# subset_df = subset_df[subset_df['WRS2'].str.slice(1,4).astype(int).isin([29])].copy()\n",
    "# subset_df = subset_df[subset_df['WRS2'].str.slice(5,8).astype(int).isin([37])].copy()\n",
    "\n",
    "# subset_df = subset_df[subset_df['SNOW_COUNT_RATIO'] < 0.1]\n",
    "# print(f'  {len(subset_df.count(axis=1))}')\n",
    "\n",
    "# subset_df = subset_df[~subset_df['WRS2'].isin(['p021r040'])].copy()\n",
    "# subset_df = subset_df[subset_df['WATER_COUNT_RATIO'] > 0.2]\n",
    "# print(f'  {len(subset_df.count(axis=1))}')\n",
    "\n",
    "# Add the high CLOUD_COVER_LAND scenes to the skip list but don't remove from the dataframe\n",
    "# Do this after pulling the scene skip list subset above\n",
    "scene_skip_list.extend(subset_df[subset_df['CLOUD_COVER_LAND'] >= 71]['SCENE_ID'].values)\n",
    "\n",
    "\n",
    "\n",
    "new_skip_scenes = []\n",
    "new_skip_count = 0\n",
    "\n",
    "for i, row in subset_df.iterrows():\n",
    "\n",
    "    scene_id = row[\"SCENE_ID\"].upper()\n",
    "\n",
    "    wrs2_path = int(scene_id[5:8])\n",
    "    wrs2_row = int(scene_id[8:11])\n",
    "    wrs2_tgt = f'{wrs2_path:03d}{wrs2_row:03d}'\n",
    "    wrs2_above = f'{wrs2_path:03d}{wrs2_row-1:03d}'\n",
    "    wrs2_below = f'{wrs2_path:03d}{wrs2_row+1:03d}'    \n",
    "\n",
    "    above_scene_id = scene_id.upper().replace(wrs2_tgt, wrs2_above)\n",
    "    above_stats_df = stats_df.loc[stats_df['SCENE_ID'] == above_scene_id]\n",
    "    if len(above_stats_df):\n",
    "        above_cloud_pct = float(above_stats_df.iloc[0]['CLOUD_COVER_LAND'])\n",
    "    else:\n",
    "        above_cloud_pct = None\n",
    "        \n",
    "    below_scene_id = scene_id.upper().replace(wrs2_tgt, wrs2_below)\n",
    "    below_stats_df = stats_df.loc[stats_df['SCENE_ID'] == below_scene_id]\n",
    "    if len(below_stats_df):\n",
    "        below_cloud_pct = float(below_stats_df.iloc[0]['CLOUD_COVER_LAND'])\n",
    "    else:\n",
    "        below_cloud_pct = None\n",
    "\n",
    "    # # Only show scenes that have above & below both skipped or None\n",
    "    # if (((above_scene_id not in scene_skip_list) and (above_cloud_pct is not None)) or \n",
    "    #     ((below_scene_id not in scene_skip_list) and (below_cloud_pct is not None))):\n",
    "    #     continue   \n",
    "    \n",
    "    landsat_type = scene_id.split('_')[0].upper()\n",
    "    landsat_img = ee.Image(f'LANDSAT/{landsat_type}/C02/T1_L2/{scene_id}')\n",
    "    landsat_region = landsat_img.geometry().bounds(1, 'EPSG:4326')\n",
    "    landsat_sr_img = landsat_img.select(rgb_bands[landsat_type]).multiply([0.0000275]).add([-0.2])\n",
    "\n",
    "    # Landsat true color image\n",
    "    landsat_url = (\n",
    "        landsat_sr_img.where(land_mask.unmask().eq(0), 0.25)\n",
    "        .getThumbURL({'min': 0.0, 'max': 0.30, 'gamma': 1.25, 'region': landsat_region, 'dimensions': image_size})\n",
    "    )\n",
    "\n",
    "    # Landsat true color with Fmask\n",
    "    fmask_url = (\n",
    "        landsat_sr_img.where(land_mask.unmask().eq(0), 0.25).visualize(min=0, max=0.3, gamma=1.25)\n",
    "        .blend(fmask(landsat_img).where(land_mask.unmask().eq(0), fmask_max).visualize(bands='fmask', min=0, max=fmask_max, palette=fmask_palette))\n",
    "        .getThumbURL({'region': landsat_region, 'dimensions': image_size})\n",
    "    )\n",
    "\n",
    "    print('#'*80)\n",
    "    print(\n",
    "        f'  {scene_id}  {row[\"TOTAL_PIXELS\"]:>10d}  {row[\"UNMASKED_PIXELS\"]:>10d}'\n",
    "        f'  ({row[\"CLOUD_COUNT_RATIO\"]:>0.2f}) ({row[\"SNOW_COUNT_RATIO\"]:>0.2f}) {row[\"CLOUD_COVER_LAND\"]}'\n",
    "        f'  {row[red_band]:0.2f}  {row[green_band]:0.2f}  {row[blue_band]:0.2f}'\n",
    "    )\n",
    "    # print(landsat_url)\n",
    "    # print(fmask_url)\n",
    "    ipyplot.plot_images([landsat_url, fmask_url], img_width=image_size)\n",
    "\n",
    "\n",
    "    # Show the images above and below the target wrs2\n",
    "    above_img = ee.Image(f'LANDSAT/{landsat_type}/C02/T1_L2/{above_scene_id}')\n",
    "    above_region = above_img.geometry().bounds(1, 'EPSG:4326')\n",
    "    above_sr_img = above_img.select(rgb_bands[landsat_type]).multiply([0.0000275]).add([-0.2])\n",
    "    try:\n",
    "        above_url = (\n",
    "            above_sr_img.where(land_mask.unmask().eq(0), 0.25).visualize(min=0, max=0.3, gamma=1.25)\n",
    "            .blend(fmask(above_img).where(land_mask.unmask().eq(0), fmask_max).visualize(bands='fmask', min=0, max=fmask_max, palette=fmask_palette))\n",
    "            .getThumbURL({'region': above_region, 'dimensions': image_size})\n",
    "        )\n",
    "    except:\n",
    "        above_url = None\n",
    "        \n",
    "    below_img = ee.Image(f'LANDSAT/{landsat_type}/C02/T1_L2/{below_scene_id}')\n",
    "    below_region = below_img.geometry().bounds(1, 'EPSG:4326')\n",
    "    below_sr_img = below_img.select(rgb_bands[landsat_type]).multiply([0.0000275]).add([-0.2])\n",
    "    try:\n",
    "        below_url = (\n",
    "            below_sr_img.where(land_mask.unmask().eq(0), 0.25).visualize(min=0, max=0.3, gamma=1.25)\n",
    "            .blend(fmask(below_img).where(land_mask.unmask().eq(0), fmask_max).visualize(bands='fmask', min=0, max=fmask_max, palette=fmask_palette))\n",
    "            .getThumbURL({'region': below_region, 'dimensions': image_size})\n",
    "        )\n",
    "    except:\n",
    "        below_url = None\n",
    "\n",
    "    above_skipped = f' (skipped)' if above_scene_id in scene_skip_list else ''   \n",
    "    below_skipped = f' (skipped)' if below_scene_id in scene_skip_list else ''\n",
    "    \n",
    "    if above_url and below_url:\n",
    "        print(f'{below_scene_id} ({below_cloud_pct}){below_skipped}  {above_scene_id} ({above_cloud_pct}){above_skipped}')\n",
    "        ipyplot.plot_images([below_url, above_url], img_width=image_size)\n",
    "    elif above_url:\n",
    "        print(f'{above_scene_id} ({above_cloud_pct}){above_skipped}')\n",
    "        ipyplot.plot_images([above_url], img_width=image_size)\n",
    "    elif below_url:\n",
    "        print(f'{below_scene_id} ({below_cloud_pct}){below_skipped}')\n",
    "        ipyplot.plot_images([below_url], img_width=image_size)\n",
    "\n",
    "\n",
    "    new_skip_scenes.append(scene_id)\n",
    "    new_skip_count += 1\n",
    "    if new_skip_count >= print_count:\n",
    "        break\n",
    "\n",
    "print('\\nDone')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebfe209-4879-4ae4-91e1-209645eb6184",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2072ae3-8019-4cea-a82e-0788899da026",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4861032-ee1d-499b-b093-97f709c7e298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Display old PTJPL images with water pixels that need to be rebuilt\n",
    "# start_year = 2015\n",
    "# end_year = 2024\n",
    "# years = list(range(start_year, end_year + 1))\n",
    "\n",
    "# print_count = 100\n",
    "# image_size = 700\n",
    "\n",
    "\n",
    "# print('Getting PTJPL scene list')\n",
    "# ptjpl_coll_id = 'projects/openet/assets/ptjpl/conus/gridmet/landsat/c02'\n",
    "# ptjpl_coll = (\n",
    "#     ee.ImageCollection(ptjpl_coll_id).filterDate('2015-09-01', f'{end_year+1}-01-01')\n",
    "#     .filterMetadata('model_version', 'not_equals', '0.4.1')\n",
    "# )\n",
    "# ptjpl_scenes = set(ptjpl_coll.aggregate_array('system:index').getInfo())\n",
    "# print(len(ptjpl_scenes))\n",
    "\n",
    "\n",
    "# print('Reading image stats CSV files')\n",
    "# stats_df_list = []\n",
    "# for wrs2_tile in wrs2_list:\n",
    "#     # if int(wrs2_tile[1:4]) not in range(10, 25):\n",
    "#     #     continue\n",
    "        \n",
    "#     for year in range(start_year, end_year + 1):\n",
    "#         wrs2_stats_path = os.path.join(stats_ws, f'{year}', f'{wrs2_tile}_{year}.csv')\n",
    "#         if not os.path.isfile(wrs2_stats_path):\n",
    "#             # print(f'  {wrs2_tile}_{year} - Missing stats CSV, skipping')\n",
    "#             continue\n",
    "#         try:\n",
    "#             wrs2_stats_df = pd.read_csv(wrs2_stats_path, index_col=False)\n",
    "#         except Exception as e:\n",
    "#             print(f'  {wrs2_tile}_{year} - Error reading CSV, skipping')\n",
    "#             continue\n",
    "#         if wrs2_stats_df.empty:\n",
    "#             continue\n",
    "#         wrs2_stats_df['DATE'] = wrs2_stats_df['SCENE_ID'].str.slice(12, 20)\n",
    "#         wrs2_stats_df['WRS2'] = 'p' + wrs2_stats_df['SCENE_ID'].str.slice(5, 8) + 'r' + wrs2_stats_df['SCENE_ID'].str.slice(8, 11)\n",
    "#         stats_df_list.append(wrs2_stats_df)\n",
    "\n",
    "# stats_df = pd.concat(stats_df_list)\n",
    "# print(f'  {len(stats_df.count(axis=1))}')\n",
    "\n",
    "\n",
    "# # Compute the ratios\n",
    "# # stats_df['ACCA_COUNT_RATIO'] = stats_df['ACCA_PIXELS'] / stats_df['TOTAL_PIXELS']\n",
    "# stats_df['SNOW_COUNT_RATIO'] = stats_df['SNOW_PIXELS'] / stats_df['TOTAL_PIXELS']\n",
    "# # stats_df['SHADOW_COUNT_RATIO'] = stats_df['SHADOW_PIXELS'] / stats_df['TOTAL_PIXELS']\n",
    "# stats_df['WATER_COUNT_RATIO'] = stats_df['WATER_PIXELS'] / stats_df['TOTAL_PIXELS']\n",
    "# stats_df['MASKED_PIXELS'] = (\n",
    "#     stats_df['CLOUD_PIXELS'] + stats_df['CIRRUS_PIXELS'] + stats_df['DILATE_PIXELS']\n",
    "#     + stats_df['SHADOW_PIXELS']\n",
    "#     + stats_df['SNOW_PIXELS']\n",
    "#     # + stats_df['WATER_PIXELS']\n",
    "#     + stats_df['ACCA_PIXELS']\n",
    "#     # + stats_df['SATURATED_PIXELS']\n",
    "# )\n",
    "# stats_df['CLOUD_COUNT_RATIO'] = stats_df['MASKED_PIXELS'] / stats_df['TOTAL_PIXELS']\n",
    "# # stats_df['CLOUD_COUNT_RATIO'] = stats_df['UNMASKED_PIXELS'] / stats_df['TOTAL_PIXELS']\n",
    "\n",
    "# # Filter to existing PTJPL scenes\n",
    "# subset_df = stats_df[stats_df[\"SCENE_ID\"].str.lower().isin(ptjpl_scenes)].copy()\n",
    "\n",
    "# # Filter to scenes with lots of water pixels\n",
    "# subset_df = subset_df[subset_df['WATER_COUNT_RATIO'] > 0.01].copy()\n",
    "# subset_df.sort_values('WATER_COUNT_RATIO', ascending=False, inplace=True)\n",
    "# # subset_df = subset_df[~subset_df['WRS2'].isin(['p021r040'])]\n",
    "# print(f'  {len(subset_df.count(axis=1))}')\n",
    "\n",
    "\n",
    "# for i, row in subset_df.iterrows():\n",
    "#     # TODO: \n",
    "#     if row[\"SCENE_ID\"].lower() not in ptjpl_scenes:\n",
    "#         continue\n",
    "\n",
    "#     scene_id = row[\"SCENE_ID\"].upper()\n",
    "\n",
    "#     wrs2_path = int(scene_id[5:8])\n",
    "#     wrs2_row = int(scene_id[8:11])\n",
    "#     wrs2_tgt = f'{wrs2_path:03d}{wrs2_row:03d}'\n",
    "#     wrs2_above = f'{wrs2_path:03d}{wrs2_row-1:03d}'\n",
    "#     wrs2_below = f'{wrs2_path:03d}{wrs2_row+1:03d}'    \n",
    "    \n",
    "#     landsat_type = scene_id.split('_')[0].upper()\n",
    "#     landsat_img = ee.Image(f'LANDSAT/{landsat_type}/C02/T1_L2/{scene_id}')\n",
    "#     landsat_region = landsat_img.geometry().bounds(1, 'EPSG:4326')\n",
    "#     landsat_sr_img = landsat_img.select(rgb_bands[landsat_type]).multiply([0.0000275]).add([-0.2])\n",
    "\n",
    "#     # Landsat true color image\n",
    "#     landsat_url = (\n",
    "#         landsat_sr_img.where(land_mask.unmask().eq(0), 0.25)\n",
    "#         .getThumbURL({'min': 0.0, 'max': 0.30, 'gamma': 1.25, 'region': landsat_region, 'dimensions': image_size})\n",
    "#     )\n",
    "\n",
    "#     # Landsat true color with Fmask\n",
    "#     fmask_url = (\n",
    "#         landsat_sr_img.where(land_mask.unmask().eq(0), 0.25).visualize(min=0, max=0.3, gamma=1.25)\n",
    "#         .blend(fmask(landsat_img).where(land_mask.unmask().eq(0), fmask_max).visualize(bands='fmask', min=0, max=fmask_max, palette=fmask_palette))\n",
    "#         .getThumbURL({'region': landsat_region, 'dimensions': image_size})\n",
    "#     )\n",
    "\n",
    "#     # PTJPL scene\n",
    "#     ptjpl_img = (\n",
    "#         ee.Image(f'{ptjpl_coll_id}/{row[\"SCENE_ID\"].lower()}')\n",
    "#         .divide(ee.Image(f'projects/openet/assets/reference_et/conus/gridmet/daily/v1/{scene_id[12:20]}').select(['eto']).resample('bilinear'))\n",
    "#     )\n",
    "#     # viridis = ['#440154', '#433982', '#30678D', '#218F8B', '#36B677', '#8ED542', '#FDE725']\n",
    "#     et_palette = ['DEC29B', 'E6CDA1', 'EDD9A6', 'F5E4A9', 'FFF4AD', 'C3E683', '6BCC5C', '3BB369', '20998F', '1C8691', '16678A', '114982', '0B2C7A']\n",
    "#     ptjpl_url = (\n",
    "#         ptjpl_img.divide(1000).where(land_mask.unmask().eq(0), 0.25).visualize(bands='et', min=0, max=1.25, palette=et_palette)\n",
    "#         .getThumbURL({'region': landsat_region, 'dimensions': image_size})\n",
    "#     )\n",
    "\n",
    "#     print('#'*80)\n",
    "#     print(\n",
    "#         f'  {scene_id}  {row[\"TOTAL_PIXELS\"]:>10d}  {row[\"UNMASKED_PIXELS\"]:>10d}'\n",
    "#         f'  ({row[\"CLOUD_COUNT_RATIO\"]:>0.2f}) ({row[\"SNOW_COUNT_RATIO\"]:>0.2f}) {row[\"CLOUD_COVER_LAND\"]}'\n",
    "#     )\n",
    "#     print(landsat_url)\n",
    "#     print(fmask_url)\n",
    "#     print(ptjpl_url)\n",
    "#     ipyplot.plot_images([landsat_url, fmask_url, ptjpl_url], img_width=image_size)\n",
    "\n",
    "# print('\\nDone')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321ab95f-95c1-4271-99ee-7e93bc5a9957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Remove existing PTJPL scenes with water pixels so they can be rerun with 0.4.1\n",
    "# start_year = 2015\n",
    "# end_year = 2023\n",
    "\n",
    "# print('Getting PTJPL scene list')\n",
    "# ptjpl_coll_id = 'projects/openet/assets/ptjpl/conus/gridmet/landsat/c02'\n",
    "# ptjpl_coll = (\n",
    "#     ee.ImageCollection(ptjpl_coll_id).filterDate('2015-09-01', f'{end_year+1}-01-01')\n",
    "#     .filterMetadata('model_version', 'not_equals', '0.4.1')\n",
    "# )\n",
    "# ptjpl_scenes = set(ptjpl_coll.aggregate_array('system:index').getInfo())\n",
    "# print(len(ptjpl_scenes))\n",
    "\n",
    "\n",
    "# print('Reading image stats CSV files')\n",
    "# stats_df_list = []\n",
    "# for wrs2_tile in wrs2_list:\n",
    "#     # if int(wrs2_tile[1:4]) not in range(10, 25):\n",
    "#     #     continue\n",
    "        \n",
    "#     for year in range(start_year, end_year + 1):\n",
    "#         wrs2_stats_path = os.path.join(stats_ws, f'{year}', f'{wrs2_tile}_{year}.csv')\n",
    "#         if not os.path.isfile(wrs2_stats_path):\n",
    "#             # print(f'  {wrs2_tile}_{year} - Missing stats CSV, skipping')\n",
    "#             continue\n",
    "#         try:\n",
    "#             wrs2_stats_df = pd.read_csv(wrs2_stats_path, index_col=False)\n",
    "#         except Exception as e:\n",
    "#             print(f'  {wrs2_tile}_{year} - Error reading CSV, skipping')\n",
    "#             continue\n",
    "#         if wrs2_stats_df.empty:\n",
    "#             continue\n",
    "#         wrs2_stats_df['DATE'] = wrs2_stats_df['SCENE_ID'].str.slice(12, 20)\n",
    "#         wrs2_stats_df['WRS2'] = 'p' + wrs2_stats_df['SCENE_ID'].str.slice(5, 8) + 'r' + wrs2_stats_df['SCENE_ID'].str.slice(8, 11)\n",
    "#         stats_df_list.append(wrs2_stats_df)\n",
    "\n",
    "# stats_df = pd.concat(stats_df_list)\n",
    "# print(f'  {len(stats_df.count(axis=1))}')\n",
    "\n",
    "\n",
    "# # Filter to existing PTJPL scenes\n",
    "# subset_df = stats_df[stats_df[\"SCENE_ID\"].str.lower().isin(ptjpl_scenes)].copy()\n",
    "\n",
    "# # Compute the ratios\n",
    "# subset_df['WATER_COUNT_RATIO'] = subset_df['WATER_PIXELS'] / subset_df['TOTAL_PIXELS']\n",
    "\n",
    "# # Filter to scenes with lots of water pixels\n",
    "# subset_df = subset_df[subset_df['WATER_COUNT_RATIO'] > 0.001].copy()\n",
    "# print(f'  {len(subset_df.count(axis=1))}')\n",
    "\n",
    "\n",
    "# # Remove the PTJPL images\n",
    "# for i, row in subset_df.iterrows():\n",
    "#     if row[\"SCENE_ID\"].lower() not in ptjpl_scenes:\n",
    "#         continue\n",
    "#     print(row[\"SCENE_ID\"])\n",
    "#     ee.data.deleteAsset(f'{ptjpl_coll_id}/{row[\"SCENE_ID\"].lower()}')\n",
    "\n",
    "# print('\\nDone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33529e92-af27-49ee-b93c-ebb52652e586",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
